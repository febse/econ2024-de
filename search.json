[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Einführung in die Ökonometrie",
    "section": "",
    "text": "1 Setup\nIn den Übungen werden wir die Programmiersprache Python verwenden, um die in der Vorlesung behandelten Themen zu erklären und an realen Daten zu üben. Die Übungen werden in Form von Jupyter Notebooks bereitgestellt, die Sie in Ihrer eigenen Umgebung ausführen können.\nDeswegen ist es notwendig, zuerst eine Arbeitsumgebung einzurichten.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Setup</span>"
    ]
  },
  {
    "objectID": "index.html#git",
    "href": "index.html#git",
    "title": "Einführung in die Ökonometrie",
    "section": "1.1 Git",
    "text": "1.1 Git\nDie Übungen werden in einem Git-Repository auf GitHub bereitgestellt. Git ist ein Versionskontrollsystem, das die Änderungen an Dateien verfolgt und es ermöglicht, verschiedene Versionen von Dateien zu speichern. GitHub ist eine Plattform, die auf Git basiert und es ermöglicht, Git-Repositories zu hosten und zu teilen.\nWir werden Git verwenden, um die Übungen herunterzuladen und um Ihre Lösungen hochzuladen.\nInstallieren Sie Git von https://git-scm.com/downloads. Wählen Sie die Version, die zu Ihrem Betriebssystem passt und folgen Sie den Anweisungen. Lassen Sie die Standardeinstellungen unverändert, es sei denn, Sie wissen ganz genau, was Sie tun.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Setup</span>"
    ]
  },
  {
    "objectID": "index.html#github-account",
    "href": "index.html#github-account",
    "title": "Einführung in die Ökonometrie",
    "section": "1.2 GitHub Account",
    "text": "1.2 GitHub Account\nFür die Übungen brauchen Sie ein GitHub.com Konto:\n\nErstellen Sie ein Konto auf https://github.com/signup.\nBei der Registrierung wählen Sie ein Passwort, das Sie nirgendwo anders verwenden. Am Ende des Semesters können Sie Ihr Passwort ändern.\nEmpfehlung: Aktivieren Sie die Zwei-Faktor-Authentifizierung (2FA) in den Einstellungen Ihres GitHub-Kontos.\nEmpfehlung: Beantragen Sie die Studentenvorteile, um kostenlosen Zugang zu GitHub Copilot zu erhalten, einem KI-gestützten Code-Completion- und Chat-Tool.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Setup</span>"
    ]
  },
  {
    "objectID": "index.html#visual-studio-code",
    "href": "index.html#visual-studio-code",
    "title": "Einführung in die Ökonometrie",
    "section": "1.3 Visual Studio Code",
    "text": "1.3 Visual Studio Code\nVisual Studio Code (VSC) ist ein Open-Source-Code-Editor, den wir für die Arbeit mit Python benutzen werden.\nInstallieren Sie Visual Studio Code von https://code.visualstudio.com/. Wählen Sie die Version, die zu Ihrem Betriebssystem passt und folgen Sie den Anweisungen.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Setup</span>"
    ]
  },
  {
    "objectID": "index.html#kursrepository-klonen",
    "href": "index.html#kursrepository-klonen",
    "title": "Einführung in die Ökonometrie",
    "section": "1.4 Kursrepository klonen",
    "text": "1.4 Kursrepository klonen\nÖffnen Sie VSC und drücken Sie Ctrl+Shift+P. Suchen Sie nach “Git: Clone” und drücken Sie Enter. Geben Sie die URL des Kursrepositories ein:\nhttp://github.com/febse/econ2024-de.git\nWählen Sie einen Ordner auf Ihrem Computer, in dem Sie das Repository speichern möchten. VSC wird das Repository herunterladen und fragen, ob Sie es öffnen möchten. Klicken Sie auf “Open”.\nWarten Sie einen Moment, bis VSC das Repository geöffnet hat. Sie sollten eine Ordnerstruktur sehen, die den Inhalt des Repositories darstellt. VSC wird Sie fragen, ob Sie die empfohlenen Erweiterungen installieren möchten. Klicken Sie auf “Install All”.\nAm Ende sollten Sie die folgenden Erweiterungen installiert haben:\n\nms-python.autopep8\nms-python.python\nms-python.debugpy\nms-vscode-remote.remote-containers\nms-toolsai.jupyter\ngithub.codespaces\ngithub.copilot\n\nDrucken Sie Ctrl+Shift+X. Dieses wird die Erweiterungsansicht öffnen. Überprüfen Sie ob alle Erweiterungen installiert sind. Falls nicht, kopieren Sie die Kennzeichen (z.B. ms-python.autopep8) der fehlenden Erweiterungen von der Liste (oben), finden Sie die Erweiterungen in der Erweiterungsansicht und installieren Sie sie manuell.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Setup</span>"
    ]
  },
  {
    "objectID": "index.html#python",
    "href": "index.html#python",
    "title": "Einführung in die Ökonometrie",
    "section": "1.5 Python",
    "text": "1.5 Python\nPython ist zurzeit eine der meistbenutzten Programmiersprachen in der Welt. Es ist einfach zu lernen und hat eine große Community, die viele Bibliotheken und Frameworks entwickelt hat. In der Welt der Datenwissenschaft werden meistens Python und R benutzt. In den letzten Jahren stieg die Popularität von Python.\n\n1.5.1 Codespaces (empfohlen)\nUm die Konfiguration zu vereinfachen, können Sie Codespaces benutzen. In den ersten Übungen werden wir eine Anleitung zeigen, wie Sie Codespaces benutzen können.\n\n\n1.5.2 Miniconda\nEs gibt viele Möglichkeiten, wie Sie Python local auf Ihrem Rechner installieren können. Hier zeigen wir die Installation mit Miniconda. Conda ist ein Paketmanager, der es ermöglicht, Python-Umgebungen zu verwalten. Eine Python-Umgebung ist eine isolierte Instanz von Python, die es ermöglicht, verschiedene Versionen von Python und verschiedenen Bibliotheken zu verwenden, ohne dass sie sich gegenseitig beeinflussen. Das ist vor allem dann nützlich, wenn Sie an verschiedenen Projekten arbeiten, die unterschiedliche Anforderungen an Python und Bibliotheken haben.\n\nLaden Sie das Miniconda Installationspaket von https://docs.conda.io/en/latest/miniconda.html für Ihr Betriebssystem.\nStarten Sie das Packet und folgen Sie den Anweisungen. Lassen Sie die Standardeinstellungen unverändert, es sei denn, Sie wissen was Sie tun.\nInstallieren Sie Conda in einem Ordner ohne Leerzeichen und nur mit ASCII Zeichen im Pfad (d.h. keine Kyrillischen Zeichen, keine Umlaute, etc.), z.B. C:\\Miniconda3 oder C:\\Users\\boyko\\Miniconda3.\nNachdem Miniconda installiert ist, öffnen Sie VSC. Drücken Sie Ctrl+Shift+P und starten Sie zu schreiben: “Python: Create environment”. Wenn die Option in dem Dropdown-Menü erscheint, wählen Sie sie und drucken Sie Enter.\nWählen Sie “Conda”.\nWählen Sie die Python-3.11 Version.\nDieses wird einen Order namens .conda erstellen.\nFalls Sie diese Schritte in dem Order des Kursrepositories gemacht haben, werden dann automatisch die notwendingen Bibliotheken installiert.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Setup</span>"
    ]
  },
  {
    "objectID": "index.html#pycharm-optional",
    "href": "index.html#pycharm-optional",
    "title": "Einführung in die Ökonometrie",
    "section": "1.6 Pycharm (optional)",
    "text": "1.6 Pycharm (optional)\nStatt VSC können Sie auch PyCharm oder DataSpell benutzen. PyCharm ist eine integrierte Entwicklungsumgebung (IDE) für Python, die von JetBrains entwickelt wurde. PyCharm ist eine der beliebtesten Python-IDEs und bietet viele Funktionen, die die Entwicklung von Python-Programmen erleichtern. Falls Sie mit PyCharm oder DataSpell experimentieren möchten, bieten wir für die Übungen kostenfreie Lizenzen an.\n\nRegistrieren Sie sich auf https://account.jetbrains.com/signup mit Ihrer Universitäts-E-Mail-Adresse (muss auf feb.uni-sofia.bg oder feba.uni-sofia.bg enden).\nLaden Sie Pycharm von https://www.jetbrains.com/pycharm/download/ herunter und installieren Sie es.\nBeim Aktivierungsdialog wählen Sie “Licence Server” und geben Sie https://febs.fls.jetbrains.com/ ein.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Setup</span>"
    ]
  },
  {
    "objectID": "00-Hausarbeit.html",
    "href": "00-Hausarbeit.html",
    "title": "Hausarbeit",
    "section": "",
    "text": "Lokal bearbeiten\nSie können die Hausaufgabe-Repository klonen und der Anleitung in 1 Setup folgen, um Ihre Pythonumgebung zu konfigurieren.",
    "crumbs": [
      "Hausarbeit"
    ]
  },
  {
    "objectID": "00-Hausarbeit.html#mit-google-colab-bearbeiten",
    "href": "00-Hausarbeit.html#mit-google-colab-bearbeiten",
    "title": "Hausarbeit",
    "section": "Mit Google Colab bearbeiten",
    "text": "Mit Google Colab bearbeiten\nSie können die Datei online in Google Colab bearbeiten. Dazu brauchen Sie nur einen Google-Account.\n\nLaden Sie die Datei index.ipynb von Ihrem Hausaufgaben-Repository herunter.\nÖffnen Sie https://colab.research.google.com/ in Ihrem Browser und klicken Sie auf Upload -&gt; Browse und wählen Sie die Datei index.ipynb aus, die Sie heruntergeladen haben.\nBearbeiten Sie die Datei und laden Sie sie nach Abschluss der Bearbeitung wieder auf Ihren lokalen Computer herunter. Um die Datei herunterzuladen, klicken Sie auf File -&gt; Download -&gt; .ipynb.",
    "crumbs": [
      "Hausarbeit"
    ]
  },
  {
    "objectID": "00-Hausarbeit.html#abgabe",
    "href": "00-Hausarbeit.html#abgabe",
    "title": "Hausarbeit",
    "section": "Abgabe",
    "text": "Abgabe\nDie Abgabe erfolgt, indem Sie Ihre Lösung (als jupyter Notebook) in das Hausaufgaben-Repository hochladen. Sie können die Datei mehremals hochladen, es wird nur die letzte Version bewertet, die bis zum Abgabetermin hochgeladen wurde. Abgaben nach dem Abgabetermin werden nicht bewertet.\n\nÖffnen Sie Ihr Hausaufgaben-Repository und klicken Sie auf Add file -&gt; Upload files.\n\n\n\n\nRepository öffnen\n\n\n\nKlicken Sie auf Choose your files und wählen Sie Ihre Lösung aus. Klicken Sie auf Commit changes, um die Datei hochzuladen.\n\n  \n\nIhre Lösung wird jetzt hochgeladen. Sie können (und sollten) kontrollieren, ob die Datei korrekt hochgeladen wurde. Öffnen Sie Ihre Hausaufgabe-Repository, suchen Sie nach index.ipynb und klicken Sie darauf, um die Datei zu öffnen. Sie sollten Ihre Lösung sehen. Falls nicht, setzen Sie sich bitte mit mir in Verbindung, um das Problem zu lösen.",
    "crumbs": [
      "Hausarbeit"
    ]
  },
  {
    "objectID": "01-Python/01-01-Basics.html",
    "href": "01-Python/01-01-Basics.html",
    "title": "2  Python Basics",
    "section": "",
    "text": "2.1 Jupyter Notebooks in VS Code\nHäufig verwendete Tastenkombinationen\nShortcuts für den Kommando-Modus (Edit Mode)\nShortcuts für den Edit Modus - Alt + Shift + ↑: Die aktuelle Zeile nach oben kopieren (Fokus bleibt auf der aktuellen Zeile) - Alt + Shift + ↓: Die aktuelle Zeile nach unten kopieren (Fokus verlagert sich zur nächsten Zeile) - Ctrl+Enter/Shift+Enter: Markierte Zelle ausführen und Fokus auf die nächste Zelle setzen\nShortcuts für beide Modi",
    "crumbs": [
      "Einführung in Python",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Python Basics</span>"
    ]
  },
  {
    "objectID": "01-Python/01-01-Basics.html#jupyter-notebooks-in-vs-code",
    "href": "01-Python/01-01-Basics.html#jupyter-notebooks-in-vs-code",
    "title": "2  Python Basics",
    "section": "",
    "text": "Enter: Bearbeitungsmodus einschalten\nEsc: Kommando-Modus einschalten\n\n\n\nA : Eine Zelle oberhalb der aktuellen Zelle einfügen\nB : Eine Zelle unterhalb der aktuellen Zelle einfügen\nAlt + ↑: Zelle nach oben verschieben\nAlt + ↓: Zelle nach unten verschieben\nAlt + Shift + ↑: Zelle nach oben kopieren (Fokus bleibt auf der aktuellen Zelle)\nAlt + Shift + ↓: Zelle nach unten kopieren (der Fokus wechselt zur nächsten Zelle)\ndd : Zelle löschen\nz : Die letzte Änderung rückgängig machen\nM : Die Zelle in eine Markdown-Zelle umwandeln\nY: Die Zelle in eine Code-Zelle umwandeln\n\n\n\n\nCtrl+Enter : Die aktuelle Zelle ausführen (Fokus bleibt auf der aktuellen Zelle)\nShift+Enter : Die aktuelle Zelle ausführen und Fokus auf die nächste Zelle setzen\nAlt+Enter : Die aktuelle Zelle ausführen und eine neue Zelle einfügen",
    "crumbs": [
      "Einführung in Python",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Python Basics</span>"
    ]
  },
  {
    "objectID": "01-Python/01-01-Basics.html#arithmetische-operationen",
    "href": "01-Python/01-01-Basics.html#arithmetische-operationen",
    "title": "2  Python Basics",
    "section": "2.2 Arithmetische Operationen",
    "text": "2.2 Arithmetische Operationen\n\n# Addition\n1 + 1\n\n2\n\n\nDie Varianz von Y ist größer als die Varianz von X. Das bedeutet, daß die Werte, die Y produziert, weiter von ihrem Erwartungswert entfernt sein werden als die Werte, die X produziert.\n\n# Division\n1 / 2\n\n0.5\n\n\n\n# Multiplikation\n2 * 3\n\n6\n\n\n\n# Potenz\n2.3 ** 8\n\n783.1098528099996\n\n\n\n# Typ\ntype(1)\n\nint\n\n\n\ntype(1.0)\n\nfloat\n\n\n\n2.2.1 Zuweisung (Assignment)\nWir können Werte Variablen zuweisen. In Python verwenden wir dazu das Gleichheitszeichen =. Der Wert auf der rechten Seite des Gleichheitszeichens wird der Variablen auf der linken Seite zugewiesen. Anders als in der Mathematik, wo die Gleichung x = 3 bedeutet, dass x gleich 3 ist, bedeutet die Zuweisung x = 3 in Python, dass der Wert 3 in der Variablen x gespeichert wird. Python speichert dann den Wert 3 im Speicher des Rechners und weist ihm den Namen x zu.\n\nx = 1\ny = 5\n\n\nx + y\n\n6\n\n\n\ntype(x)\n\nint\n\n\n\n\n2.2.2 Zeichenketten (Strings)\nAußer Zahlen können wir auch Zeichenketten (Strings) speichern.\n\nz = \"Hallo, Welt!\"\nz\n\n'Hallo, Welt!'\n\n\n\nprint(z)\n\nHallo, Welt!\n\n\nZeichenketten können wir mit + verketten.\n\nz1 = z + \" Ich bin da!\"\nprint(z1)\n\nHallo, Welt! Ich bin da!\n\n\nZeichenketten können wir mit * “vervielfachen”.\n\nprint(z * 3)\n\nHallo, Welt!Hallo, Welt!Hallo, Welt!\n\n\nZeichenketten können wir mit len die Länge (Anzahl der Zeichen) bestimmen.\n\nlen(z)\n\n12\n\n\nZeichenketten können wir mit split in eine Liste von Wörtern aufteilen.\n\nz.split(\",\")\n\n['Hallo', ' Welt!']\n\n\n\nz.split(\" \")\n\n['Hallo,', 'Welt!']\n\n\nWir können Teile einer Zeichenkette mit eckigen Klammern auswählen. Dabei beginnt der Index bei 0.\n\nz[0]\n\n'H'\n\n\n\nz[1]\n\n'a'\n\n\n\nz[0:5]\n\n'Hallo'\n\n\n\nfor char in z:\n    print(char)\n\nH\na\nl\nl\no\n,\n \nW\ne\nl\nt\n!\n\n\n\n\n2.2.3 Logische Werte (Booleans)\nIn Python gibt es auch logische Werte (Booleans). Diese können nur zwei Werte annehmen: True und False. In den meisten Fällen werden wir diese Werte verwenden, um Bedingungen zu formulieren.\n\n1 &gt; 2\n\nFalse\n\n\n\n1 &lt; 3\n\nTrue\n\n\n\n2 == 2\n\nTrue\n\n\n\n\"hallo\" == \"hallo\"\n\nTrue\n\n\n\n\"hallo\" == \"Hallo\"\n\nFalse",
    "crumbs": [
      "Einführung in Python",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Python Basics</span>"
    ]
  },
  {
    "objectID": "01-Python/01-01-Basics.html#listen-und-tupel",
    "href": "01-Python/01-01-Basics.html#listen-und-tupel",
    "title": "2  Python Basics",
    "section": "2.3 Listen und Tupel",
    "text": "2.3 Listen und Tupel\nIn vielen Fällen werden wir nicht nur einzelne Werte, sondern mehrere Werte zusammen verwenden wollen. Als Beispiel nehmen wir eine Liste mit monatlichem Stromverbrauch eines Unternehmens (für 12 Monate in EUR).\n\nstromverbrauch = [100, 120, 80, 90, 110, 100, 120, 80, 90.12, 110, 100, 120.22]\n\nWir können auf einzelne Elemente einer Liste zugreifen, indem wir den Index des Elements in eckigen Klammern hinter den Namen der Liste schreiben. Wie in den meisten Programmiersprachen beginnt der Index bei 0.\n\nstromverbrauch[0]\n\n100\n\n\n\nstromverbrauch[1]\n\n120\n\n\n\nstromverbrauch[11]\n\n120.22\n\n\nVersuchen wir auf ein Element zuzugreifen, das nicht existiert, erhalten wir einen Fehler.\n\n# stromverbrauch[12]\n\nDie Länge einer Liste können wir mit der Funktion len bestimmen. Diese gibt uns die Anzahl der Elemente in der Liste zurück.\n\nlen(stromverbrauch)\n\n12\n\n\nWir können auch auf die letzten Elemente einer Liste zugreifen, indem wir negative Indizes verwenden.\n\nstromverbrauch[len(stromverbrauch) - 1]\n\n120.22\n\n\n\nstromverbrauch[-1]\n\n120.22\n\n\nWir können auch auf mehrere Elemente einer Liste zugreifen, indem wir den Index des ersten Elements und den Index des letzten Elements in eckigen Klammern hinter den Namen der Liste schreiben. Der Index des letzten Elements ist dabei exklusiv.\n\nstromverbrauch[0:3]\n\n[100, 120, 80]\n\n\nDas ist das gleiche wie\n\nstromverbrauch[:3]\n\n[100, 120, 80]\n\n\n\nstromverbrauch[0:3] == stromverbrauch[:3]\n\nTrue\n\n\n\nstromverbrauch[3:6]\n\n[90, 110, 100]\n\n\nWir können einzelne Elemente einer Liste auch verändern.\n\nstromverbrauch[0] = 1\nstromverbrauch\n\n[1, 120, 80, 90, 110, 100, 120, 80, 90.12, 110, 100, 120.22]\n\n\nWir können auch mehrere Elemente einer Liste auf einmal verändern.\n\nstromverbrauch[0:3] = [5, 5, 8]\nstromverbrauch\n\n[5, 5, 8, 90, 110, 100, 120, 80, 90.12, 110, 100, 120.22]\n\n\nTuple sind wie Listen, nur dass sie nicht verändert werden können. Wir können sie mit runden Klammern erstellen. Im folgenden Beispiel erstellen wir ein Tuple mit den Monatsnamen. Dann versuchen wir, das erste Element zu verändern. Das funktioniert nicht.\n\nmonatsnamen = (\"Januar\", \"Februar\", \"März\", \"April\", \"Mai\", \"Juni\", \"Juli\",\n               \"August\", \"September\", \"Oktober\", \"November\", \"Dezember\")\n\n\n# monatsnamen[0] = \"Jänner\"\n\n\n2.3.1 Schleifen\nIn vielen Fällen wollen wir eine Operation auf alle Elemente einer Liste anwenden. Dafür können wir Schleifen verwenden.\n\nfor g in stromverbrauch:\n    print(f\"Der Stromverbrauch war {g} EUR\")\n\nDer Stromverbrauch war 5 EUR\nDer Stromverbrauch war 5 EUR\nDer Stromverbrauch war 8 EUR\nDer Stromverbrauch war 90 EUR\nDer Stromverbrauch war 110 EUR\nDer Stromverbrauch war 100 EUR\nDer Stromverbrauch war 120 EUR\nDer Stromverbrauch war 80 EUR\nDer Stromverbrauch war 90.12 EUR\nDer Stromverbrauch war 110 EUR\nDer Stromverbrauch war 100 EUR\nDer Stromverbrauch war 120.22 EUR\n\n\n\nfor idx, g in enumerate(stromverbrauch):\n    print(f\"Der Stromverbrauch im Monat {monatsnamen[idx]} war {g} EUR.\")\n\nDer Stromverbrauch im Monat Januar war 5 EUR.\nDer Stromverbrauch im Monat Februar war 5 EUR.\nDer Stromverbrauch im Monat März war 8 EUR.\nDer Stromverbrauch im Monat April war 90 EUR.\nDer Stromverbrauch im Monat Mai war 110 EUR.\nDer Stromverbrauch im Monat Juni war 100 EUR.\nDer Stromverbrauch im Monat Juli war 120 EUR.\nDer Stromverbrauch im Monat August war 80 EUR.\nDer Stromverbrauch im Monat September war 90.12 EUR.\nDer Stromverbrauch im Monat Oktober war 110 EUR.\nDer Stromverbrauch im Monat November war 100 EUR.\nDer Stromverbrauch im Monat Dezember war 120.22 EUR.\n\n\nDie Namen der Variablen in der for-Schleife können wir frei wählen (diese müssen allerdings valide Variablennamen sein).\n\nfor i, verbrauch in enumerate(stromverbrauch):\n    print(f\"Der Stromverbrauch im Monat {monatsnamen[i]} war {verbrauch} EUR.\")\n\nDer Stromverbrauch im Monat Januar war 5 EUR.\nDer Stromverbrauch im Monat Februar war 5 EUR.\nDer Stromverbrauch im Monat März war 8 EUR.\nDer Stromverbrauch im Monat April war 90 EUR.\nDer Stromverbrauch im Monat Mai war 110 EUR.\nDer Stromverbrauch im Monat Juni war 100 EUR.\nDer Stromverbrauch im Monat Juli war 120 EUR.\nDer Stromverbrauch im Monat August war 80 EUR.\nDer Stromverbrauch im Monat September war 90.12 EUR.\nDer Stromverbrauch im Monat Oktober war 110 EUR.\nDer Stromverbrauch im Monat November war 100 EUR.\nDer Stromverbrauch im Monat Dezember war 120.22 EUR.",
    "crumbs": [
      "Einführung in Python",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Python Basics</span>"
    ]
  },
  {
    "objectID": "01-Python/01-01-Basics.html#dictionaries",
    "href": "01-Python/01-01-Basics.html#dictionaries",
    "title": "2  Python Basics",
    "section": "4.1 Dictionaries",
    "text": "4.1 Dictionaries\nEs is sehr häufig, dass wir nicht nur einzelne Werte, sondern ganze Datensätze verwenden wollen. Dafür können wir Dictionaries verwenden. Dictionaries sind wie Listen, nur dass wir nicht mit Indizes, sondern mit Schlüsseln auf die Elemente zugreifen. Schlüssel können beliebige unveränderbare Datentypen sein (z.B. Strings, Zahlen, Tupel). Werte können beliebige Datentypen sein. Wir können Dictionaries mit geschweiften Klammern erstellen. Die Werte in einem Dictionary werden mit einem Doppelpunkt vom Schlüssel getrennt. Die einzelnen Elemente werden mit Kommas getrennt.\nDie Ordnung der Elemente ist nicht definiert.\n\nstromverbrauch_dict = {\n    \"Januar\": 100,\n    \"Februar\": 120,\n    \"März\": 80,\n    \"April\": 90,\n    \"Mai\": 110,\n    \"Juni\": 100,\n    \"Juli\": 120,\n    \"August\": 80,\n    \"September\": 90.12,\n    \"Oktober\": 110,\n    \"November\": 100,\n    \"Dezember\": 120.22\n}\n\n\nstromverbrauch_dict[\"Januar\"]\n\n100\n\n\n\n# stromverbrauch_dict[\"FDFFF\"]\n\nWir können auf\n\nstromverbrauch_dict.get(\"Januar\")\n\n100\n\n\n\n# stromverbrauch_dict.get(\"FDFF\") == None\n\nWir können über die Schlüssel eines Dictionaries iterieren.\n\nfor key in stromverbrauch_dict:\n    print(key)\n\nJanuar\nFebruar\nMärz\nApril\nMai\nJuni\nJuli\nAugust\nSeptember\nOktober\nNovember\nDezember\n\n\nWir können auch über die Schlüssel und Werte eines Dictionaries iterieren.\n\nfor key, value in stromverbrauch_dict.items():\n    print(f\"Im {key} war der Stromverbrauch {value} EUR.\")\n\nIm Januar war der Stromverbrauch 100 EUR.\nIm Februar war der Stromverbrauch 120 EUR.\nIm März war der Stromverbrauch 80 EUR.\nIm April war der Stromverbrauch 90 EUR.\nIm Mai war der Stromverbrauch 110 EUR.\nIm Juni war der Stromverbrauch 100 EUR.\nIm Juli war der Stromverbrauch 120 EUR.\nIm August war der Stromverbrauch 80 EUR.\nIm September war der Stromverbrauch 90.12 EUR.\nIm Oktober war der Stromverbrauch 110 EUR.\nIm November war der Stromverbrauch 100 EUR.\nIm Dezember war der Stromverbrauch 120.22 EUR.",
    "crumbs": [
      "Einführung in Python",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Python Basics</span>"
    ]
  },
  {
    "objectID": "01-Python/01-01-Basics.html#klassen-und-objekte",
    "href": "01-Python/01-01-Basics.html#klassen-und-objekte",
    "title": "2  Python Basics",
    "section": "5.1 Klassen und Objekte",
    "text": "5.1 Klassen und Objekte\nBisher haben wir verschiedene Datentypen gesehen, drei verschiedene Datenstrukturen (Listen, Tupel und Dictionaries) und Funktionen gesehen. In Python gibt es auch Objekte, die Daten und Funktionen zusammenbinden. Funktionen, die zu einem Objekt gehören, nennen wir Methoden. Objekte werden aus Klassen erstellt. Klassen sind wie Baupläne für Objekte. In den Übungen werden wir keine Klassen selber definieren, allerdings werden wir Objekte wie DataFrame, Series, etc. verwenden, die aus Klassen erstellt wurden. Deswegen ist es wichtig, dass Sie wissen, wie Sie mit Objekten umgehen können.\nZuerst definieren wir eine Klasse Person. Diese hat zwei Attribute: name und age. Die Klasse erlaubt uns, ein Objekt zu erstellen, das diese beiden Attribute hat. Wir können auch eine Methode say_hello definieren, die uns erlaubt, “Hallo” und den Namen der Person auszugeben. Alle Methoden, wie z.B. say_hello erhalten das Argument self, das das Objekt selbst ist. Dadurch können wir über Methoden auf die Eigenschaften des Objekts zugreifen.\n\nclass Person:\n    def __init__(self, name, age):\n        self.name = name\n        self.age = age\n\n    def say_hello(self):\n        print(\"Hi, my name is\", self.name, \"and I am\", self.age, \"years old.\")\n\n\nivan = Person(\"Ivan\", 20)\nbetty = Person(\"Betty\", 25)\n\nprint(ivan.name)\nprint(ivan.age)\n\nIvan\n20\n\n\n\nivan.say_hello()\n\nHi, my name is Ivan and I am 20 years old.\n\n\n\nbetty.say_hello()\n\nHi, my name is Betty and I am 25 years old.\n\n\n\n5.1.1 Lambdafunktionen\nManchmal möchten wir eine Funktion nur einmal verwenden. Dafür können wir Lambda Funktionen verwenden. Diese Funktionen haben keinen Namen. Wir können sie mit dem Schlüsselwort lambda erstellen. Die Argumente der Funktion werden durch ein Komma getrennt hinter dem Schlüsselwort lambda geschrieben. Der Rückgabewert der Funktion wird nach einem Doppelpunkt geschrieben.\nZum Beispiel können wir eine Lambdafunktion verwenden, um den Stromverbrauch in BGN zu berechnen.\n\nstromverbrauch_bgn = map(lambda x: x * 1.955, stromverbrauch)",
    "crumbs": [
      "Einführung in Python",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Python Basics</span>"
    ]
  },
  {
    "objectID": "01-Python/01-02-Basics-Ex.html",
    "href": "01-Python/01-02-Basics-Ex.html",
    "title": "3  Übung: Python Basics",
    "section": "",
    "text": "3.0.1 Aufgabe 1\n\nBerechnen Sie die Summe der Zahlen 32.8 und 45.1\nBerechnen Sie die Differenz der Zahlen 32.8 und 45.1\nSpeichern Sie die Zahl 32.8 in a und die Zahl 45.1 in b. Berechnen Sie das Verhältnis von a zu b und speichern Sie das Ergebnis in c.\n\n\n\n3.0.2 Aufgabe 2\nErstellen Sie eine Liste mit den Zahlen 1, 2, 3, 4, 5, 6, 7, 8, 9, 10 und speichern Sie diese in der Variable numbers. - Geben Sie die Liste aus (mit print()) - Geben Sie das erste Element der Liste aus - Geben Sie das letzte Element der Liste aus - Geben Sie das dritte Element der Liste aus - Geben Sie das dritte und das siebte Element der Liste aus - Ersetzen Sie das vierte Element der Liste durch die Zahl 42\n\n\n3.0.3 Aufgabe 3\nErstellen Sie zwei Listen names und ages mit den folgenden Elementen: - names: “Alice”, “Bob”, “Charlie”, “Dave”, “Eve” - ages: 17, 42, 30, 37, 21\n\nGeben Sie die Liste names aus\nSchreiben Sie eine for-Schleife, die die Namen und das Alter der Personen ausdruckt. Die Ausgabe soll folgendermaßen aussehen: “Alice ist 23 Jahre alt”\nSie möchten nur die Namen der Personen ausdrucken, die älter als 30 Jahre sind. Schreiben Sie eine for-Schleife, die das tut.\nSie möchten eine neue Liste erstellen, die nur die Namen der Personen enthält, die älter als 30 Jahre sind. Schreiben Sie eine Listenabstraktion, die das tut.\n\n\n\n3.0.4 Aufgabe 4\nIn dieser Aufgabe werden wir eine Funktion is_in_list schreiben, die einen Namen als Argument annimmt und True oder False zurückgibt, falls der Name einer Person entspricht, die in der Liste names aus Aufgabe 3 enthalten ist.\n\n\n3.0.5 Aufgabe 5\nIn dieser Aufgabe werden wir eine Funktion get_age schreiben, die einen Namen als Argument annimmt und das Alter der Person zurückgibt, falls der Name einer Person entspricht, die in der Liste names aus Aufgabe 3 enthalten ist. Falls der Name nicht in der Liste enthalten ist, soll die Funktion None zurückgeben.\n\n\n3.0.6 Aufgabe 6\nIn dieser Aufgabe werden wir eine Funktion is_eligible schreiben, die True, False oder None zurückgibt, je nachdem ob eine Person wahlberechtigt ist oder nicht. Die Funktion soll einen Namen als Argument annehmen und das Alter der Person zurückgeben, falls der Name einer Person entspricht, die in der Liste names aus Aufgabe 3 enthalten ist. Falls der Name nicht in der Liste enthalten ist, soll die Funktion None zurückgeben. Falls der Name in der Liste enthalten ist, soll die Funktion True zurückgeben, falls die Person älter als 18 Jahre ist, andernfalls soll die Funktion False zurückgeben.\n\n\n3.0.7 Aufgabe 7\nIn dieser Aufgabe werden wir ein Dictionary erstellen, das die Namen aus Aufgabe 3 als Schlüssel und die Alter aus Aufgabe 3 als Werte enthält. Speichern Sie das Dictionary in der Variable persons.\n\nBenutzen Sie das Dictionary, um das Alter von Bob auszudrucken.\nÄndern Sie das Alter von Alice auf 43 Jahre.\nFügen Sie eine neue Person “Frank” mit dem Alter 33 Jahre hinzu.\nSchreiben Sie eine for-Schleife, die die Namen und das Alter der Personen ausdruckt. Die Ausgabe soll folgendermaßen aussehen: “Alice ist 23 Jahre alt”\nSie möchten nur die Namen der Personen ausdrucken, die mit “A” anfangen. Schreiben Sie eine for-Schleife, die über persons iteriert und das tut.",
    "crumbs": [
      "Einführung in Python",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Übung: Python Basics</span>"
    ]
  },
  {
    "objectID": "01-Python/01-03-Numpy.html",
    "href": "01-Python/01-03-Numpy.html",
    "title": "4  NumPy",
    "section": "",
    "text": "In der vorherigen Lektion haben wir uns mit Listen beschäftigt. Diese sind sehr flexibel, aber auch sehr langsam. Mit kleinen Listen werden wir das nicht merken, aber wenn wir mit großen Datenmengen arbeiten, dann können lange Laufzeiten zum Problem werden.\nNumPy (Numerical Python) ist ein Paket, das viele Funktionen enthält, die für die Arbeit mit großen Datenmengen geeignet sind.\n\nimport numpy as np\nfrom time import process_time\n\n\n# Wir können eine Liste in ein NumPy-Array umwandeln\npython_list = range(int(1e6))\nnumpy_array = np.array(python_list)\n\n\nstart_zeit = process_time()\n\na_list_plus_2 = [i + 2 for i in python_list]\n\nend_zeit = process_time()\nround(end_zeit - start_zeit, 5)\n\n0.03542\n\n\n\nstart_zeit_1 = process_time()\n\na_array_plus_2 = numpy_array + 2\n\nend_zeit_1 = process_time()\nround(end_zeit_1 - start_zeit_1, 5)\n\n0.00245\n\n\n\nx = np.array([2, 7, 5, 2])\ny = np.ones(4)\ny\n\narray([1., 1., 1., 1.])\n\n\nNumPy-Arrays sind sehr ähnlich zu Listen, aber sie haben einige zusätzliche Eigenschaften. Zum Beispiel können wir mit NumPy-Arrays rechnen. Wenn wir zwei NumPy-Arrays addieren, dann werden die Elemente an der gleichen Stelle addiert. Diese Syntax ist sehr intuitiv und einfach zu lesen.\n\nz1 = x + 1 \nz2 = x + y\nz1\n\narray([3, 8, 6, 3])\n\n\n\nz2\n\narray([3., 8., 6., 3.])\n\n\nDasselbe funktioniert mit Python-Listen nicht. Wenn wir zwei Listen addieren, dann werden die Elemente an der gleichen Stelle nicht addiert, sondern die Listen werden aneinander gehängt.\n\nx_list = [2, 7, 5, 2]\ny_list = [1, 1, 1, 1]\nx_plus_y_list = x_list + y_list\nx_plus_y_list\n\n[2, 7, 5, 2, 1, 1, 1, 1]\n\n\n\n# x_list + 1\n\nNumPy-Arrays haben auch einige Methoden, die wir mit Listen nicht haben. Zum Beispiel können wir die Summe aller Elemente eines Arrays berechnen.\n\n# Summe der Elemente\nx.sum()\n\n16\n\n\n\n# Durchschnitt der Elemente (Arithmetischer Mittelwert)\n\nx.mean()\n\n4.0\n\n\n\n# Standardabweichung\nx.std()\n\n2.1213203435596424\n\n\n\n# Minimum\nx.min()\n\n2\n\n\n\n# Maximum\nx.max()\n\n7\n\n\n\n# Der Index des Minimums\nx.argmin()\n\n0\n\n\n\n# Der Index des Maximums\nx.argmax()\n\n1\n\n\n\n4.0.1 Slicing\nWir können auch auf die Elemente eines Arrays zugreifen, indem wir einen Index angeben. Der Index beginnt bei 0.\n\nz = np.array([\"a\", \"b\", \"c\", \"d\", \"e\"])\n\n\n# Das erste Element\nz[0]\n\n'a'\n\n\n\n# Alle Elemente bis zur Indexposition 2 (exklusive)\n# Achten Sie darauf, dass der Index 0-basiert ist und daher das dritte Element ist eine Indexposition 2 hat\nz[:2]\n\narray(['a', 'b'], dtype='&lt;U1')\n\n\n\nz[-3]\n\n'c'\n\n\n\nz[-3:]\n\narray(['c', 'd', 'e'], dtype='&lt;U1')\n\n\n\nz[1:3]\n\narray(['b', 'c'], dtype='&lt;U1')\n\n\n\nz[::2]\n\narray(['a', 'c', 'e'], dtype='&lt;U1')\n\n\n\nz[::-1]\n\narray(['e', 'd', 'c', 'b', 'a'], dtype='&lt;U1')\n\n\n\n\n4.0.2 Arrays und Listen Zuweisung\nEine zugängige Erläuterung, wie Werte im Speicher des Rechners gespeichert werden, finden Sie in hier.\n\nz[1] = \"x\"\nz\n\narray(['a', 'x', 'c', 'd', 'e'], dtype='&lt;U1')\n\n\n\nz1 = z\n\n\nz[0] = \"X\"\n\n\nz1\n\narray(['X', 'x', 'c', 'd', 'e'], dtype='&lt;U1')\n\n\n\nz1 == z\n\narray([ True,  True,  True,  True,  True])\n\n\n\nprint(id(z1))\nprint(id(z))\n\n140331165885584\n140331165885584\n\n\n\nl1 = [1, 2, 3]\nl2 = l1\n\nprint(id(l1))\nprint(id(l2))\n\n140332161329216\n140332161329216\n\n\n\ns1 = \"Some string\"\ns2 = s1\n\nprint(id(s1))\nprint(id(s2))\n\n# s1[0] = \"X\"\n\n140332161347184\n140332161347184",
    "crumbs": [
      "Einführung in Python",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>NumPy</span>"
    ]
  },
  {
    "objectID": "01-Python/01-04-Pandas.html",
    "href": "01-Python/01-04-Pandas.html",
    "title": "5  Pandas",
    "section": "",
    "text": "5.1 Series\nDie einfachste Datenstruktur in Pandas ist die Series. Eine Series ist eine eindimensionale Datenstruktur, die mit einem NumPy-Array vergleichbar ist. Eine Series kann mit der Funktion pd.Series() erstellt werden. Als Argument wird ein Array übergeben. Die Series hat einen Index, der standardmäßig mit 0 beginnt. Der Index kann mit dem Argument index angepasst werden. Der Index kann ein Array von Strings sein, um die Elemente der Series zu benennen.\n# Erstellen einer Series\ns = pd.Series([1, 2, 3, 4, 5])\ns\n\n0    1\n1    2\n2    3\n3    4\n4    5\ndtype: int64\n# Erstellen einer Series mit Index\ns1 = pd.Series([1, 2, 3, 4, 5], index=['a', 'b', 'c', 'd', 'e'])\ns1\n\na    1\nb    2\nc    3\nd    4\ne    5\ndtype: int64\nDie Series hat eine Reihe von Methoden, die aufgerufen werden können. Eine Übersicht über die Methoden kann mit help(pd.Series) aufgerufen werden. Die wichtigsten Methoden sind:\n# Zugriff auf den Index\ns1.index\n\nIndex(['a', 'b', 'c', 'd', 'e'], dtype='object')\n# Zugriff auf die Werte\ns1.values\n\narray([1, 2, 3, 4, 5])\n# Zugriff auf ein Element\ns1['a']\n\n1\n# Zugriff auf mehrere Elemente\ns1[['a', 'c', 'e']]\n\na    1\nc    3\ne    5\ndtype: int64\n# Zugriff auf ein Element mit dem Ganzzahl-Index\ns1.iloc[0]\n\n1\n# Zugriff auf mehrere Elemente mit dem Index\ns1.loc[\"a\"]\n\n1\ns1.loc[[\"a\", \"c\", \"e\"]]\n\na    1\nc    3\ne    5\ndtype: int64\ns1.sum()\n\n15\ns1.mean()\n\n3.0\ns1.std()\n\n1.5811388300841898",
    "crumbs": [
      "Einführung in Python",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Pandas</span>"
    ]
  },
  {
    "objectID": "01-Python/01-04-Pandas.html#dataframe",
    "href": "01-Python/01-04-Pandas.html#dataframe",
    "title": "5  Pandas",
    "section": "5.2 DataFrame",
    "text": "5.2 DataFrame\nDas wichtigste Datenobjekt in Pandas ist der DataFrame. Ein DataFrame ist eine zweidimensionale Datenstruktur, die mit einer Tabelle vergleichbar ist. Ein DataFrame kann mit der Funktion pd.DataFrame() erstellt werden. Als Argument wird ein Array übergeben. Der DataFrame hat einen Index, der standardmäßig mit 0 beginnt. Der Index kann mit dem Argument index angepasst werden. Der Index kann ein Array von Strings sein, um die Zeilen des DataFrame zu benennen. Die Spalten des DataFrame können mit dem Argument columns benannt werden.\n\ndf = pd.DataFrame([[1, 2, 3], [4, 5, 6], [7, 7, 9], [10, 11, 12]], columns=['A', 'B', 'C'])\ndf\n\n\n\n\n\n\n\n\nA\nB\nC\n\n\n\n\n0\n1\n2\n3\n\n\n1\n4\n5\n6\n\n\n2\n7\n7\n9\n\n\n3\n10\n11\n12\n\n\n\n\n\n\n\n\ndf1 = pd.DataFrame([[1, 2, 3], [4, 5, 6], [7, 7, 9], [10, 11, 12]],\n                   index=['a', 'b', 'c', 'd'],\n                   columns=['X', 'Y', 'Z']\n                   )\ndf1\n\n\n\n\n\n\n\n\nX\nY\nZ\n\n\n\n\na\n1\n2\n3\n\n\nb\n4\n5\n6\n\n\nc\n7\n7\n9\n\n\nd\n10\n11\n12\n\n\n\n\n\n\n\nDie DataFrame hat eine Reihe von Methoden, die aufgerufen werden können. Eine Übersicht über die Methoden kann mit help(pd.DataFrame) aufgerufen werden. Die wichtigsten Methoden sind:\n\ndf1[\"X\"].sum()\n\n22\n\n\n\ndf1[\"X\"].mean()\n\n5.5\n\n\n\ndf1[\"X\"].std()\n\n3.872983346207417\n\n\n\ndf1[\"X\"].describe()\n\ncount     4.000000\nmean      5.500000\nstd       3.872983\nmin       1.000000\n25%       3.250000\n50%       5.500000\n75%       7.750000\nmax      10.000000\nName: X, dtype: float64",
    "crumbs": [
      "Einführung in Python",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Pandas</span>"
    ]
  },
  {
    "objectID": "01-Python/01-04-Pandas.html#axes",
    "href": "01-Python/01-04-Pandas.html#axes",
    "title": "5  Pandas",
    "section": "5.3 Axes",
    "text": "5.3 Axes\nDie axes eines DataFrame sind die Zeilen und Spalten des DataFrame. Die Zeilen können mit df.index und die Spalten mit df.columns abgerufen werden. Die Eigenschaft (property) shape gibt die Anzahl der Zeilen und Spalten des DataFrame zurück.\n\ndf1.shape\n\n(4, 3)\n\n\nViele Methoden können auf die Zeilen und Spalten des DataFrame angewendet werden.\n\ndf1\n\n\n\n\n\n\n\n\nX\nY\nZ\n\n\n\n\na\n1\n2\n3\n\n\nb\n4\n5\n6\n\n\nc\n7\n7\n9\n\n\nd\n10\n11\n12\n\n\n\n\n\n\n\n\ndf1.mean(axis=0)\n\nX    5.50\nY    6.25\nZ    7.50\ndtype: float64\n\n\n\ndf1.mean(axis=1)\n\na     2.000000\nb     5.000000\nc     7.666667\nd    11.000000\ndtype: float64\n\n\n\ndf1.mean()\n\nX    5.50\nY    6.25\nZ    7.50\ndtype: float64",
    "crumbs": [
      "Einführung in Python",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Pandas</span>"
    ]
  },
  {
    "objectID": "01-Python/01-04-Pandas.html#neue-spalte-hinzufügen",
    "href": "01-Python/01-04-Pandas.html#neue-spalte-hinzufügen",
    "title": "5  Pandas",
    "section": "5.4 Neue Spalte hinzufügen",
    "text": "5.4 Neue Spalte hinzufügen\nEine neue Spalte kann zu einem DataFrame hinzugefügt werden, indem ein neues Array als Wert der neuen Spalte zugewiesen wird. Die neue Spalte wird automatisch an das Ende des DataFrame hinzugefügt.\n\ndf1[\"New\"] = [1, 2, 3, 4]\ndf1.head()\n\n\n\n\n\n\n\n\nX\nY\nZ\nNew\n\n\n\n\na\n1\n2\n3\n1\n\n\nb\n4\n5\n6\n2\n\n\nc\n7\n7\n9\n3\n\n\nd\n10\n11\n12\n4\n\n\n\n\n\n\n\nHäufig wird eine neue Spalte aus bestehenden Spalten berechnet. Dazu können die bestehenden Spalten wie normale Arrays verwendet werden. Die neue Spalte wird automatisch an das Ende des DataFrame hinzugefügt.\n\ndf1[\"X_min_Y\"] = df1[\"X\"] - df1[\"Y\"]\ndf1.head()\n\n\n\n\n\n\n\n\nX\nY\nZ\nNew\nX_min_Y\n\n\n\n\na\n1\n2\n3\n1\n-1\n\n\nb\n4\n5\n6\n2\n-1\n\n\nc\n7\n7\n9\n3\n0\n\n\nd\n10\n11\n12\n4\n-1\n\n\n\n\n\n\n\n\ndf1[\"X_2\"] = 2 *df1[\"X\"]\ndf1.head()\n\n\n\n\n\n\n\n\nX\nY\nZ\nNew\nX_min_Y\nX_2\n\n\n\n\na\n1\n2\n3\n1\n-1\n2\n\n\nb\n4\n5\n6\n2\n-1\n8\n\n\nc\n7\n7\n9\n3\n0\n14\n\n\nd\n10\n11\n12\n4\n-1\n20",
    "crumbs": [
      "Einführung in Python",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Pandas</span>"
    ]
  },
  {
    "objectID": "01-Python/01-04-Pandas.html#selektieren-von-zeilen",
    "href": "01-Python/01-04-Pandas.html#selektieren-von-zeilen",
    "title": "5  Pandas",
    "section": "5.5 Selektieren von Zeilen",
    "text": "5.5 Selektieren von Zeilen\nHäufig möchten wir nur eine Teilmenge der Zeilen eines DataFrame selektieren, z.B. die ersten 5 Zeilen oder die Zeilen, die eine bestimmte Bedingung erfüllen (z.B. Männer/Frauen, beschäftigt/arbeitslos, etc.).\n\n# Als Beispiel wählen wir die ersten drei Zeilen\n\ndf1.iloc[0:2]\n\n\n\n\n\n\n\n\nX\nY\nZ\nNew\nX_min_Y\nX_2\n\n\n\n\na\n1\n2\n3\n1\n-1\n2\n\n\nb\n4\n5\n6\n2\n-1\n8\n\n\n\n\n\n\n\n\n# Als anderes Beispiel wählen wir die Zeilen, für die X größer als 3 ist\n\ndf1[df1[\"X\"] &gt; 3]\n\n\n\n\n\n\n\n\nX\nY\nZ\nNew\nX_min_Y\nX_2\n\n\n\n\nb\n4\n5\n6\n2\n-1\n8\n\n\nc\n7\n7\n9\n3\n0\n14\n\n\nd\n10\n11\n12\n4\n-1\n20",
    "crumbs": [
      "Einführung in Python",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Pandas</span>"
    ]
  },
  {
    "objectID": "01-Python/01-04-Pandas.html#selektieren-von-spalten",
    "href": "01-Python/01-04-Pandas.html#selektieren-von-spalten",
    "title": "5  Pandas",
    "section": "5.6 Selektieren von Spalten",
    "text": "5.6 Selektieren von Spalten\nHäufig möchten wir nur eine Teilmenge der Spalten eines DataFrame selektieren, z.B. die Spalten, die für eine bestimmte Analyse relevant sind.\n\ndf1[[\"X\", \"Y\"]]\n\n\n\n\n\n\n\n\nX\nY\n\n\n\n\na\n1\n2\n\n\nb\n4\n5\n\n\nc\n7\n7\n\n\nd\n10\n11",
    "crumbs": [
      "Einführung in Python",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Pandas</span>"
    ]
  },
  {
    "objectID": "01-Python/01-04-Pandas.html#groupby",
    "href": "01-Python/01-04-Pandas.html#groupby",
    "title": "5  Pandas",
    "section": "5.7 GroupBy",
    "text": "5.7 GroupBy\nMit der Funktion groupby() können die Daten in einem DataFrame gruppiert werden. Die Funktion groupby() gibt ein DataFrameGroupBy-Objekt zurück. Mit diesem Objekt können verschiedene Aggregationsfunktionen aufgerufen werden. Die wichtigsten Aggregationsfunktionen sind: - count(): Anzahl der Elemente - sum(): Summe der Elemente - mean(): Mittelwert der Elemente - median(): Median der Elemente - min(): Minimum der Elemente - max(): Maximum der Elemente - std(): Standardabweichung der Elemente - var(): Varianz der Elemente - describe(): Statistische Kennzahlen der Elemente - first(): Erstes Element - last(): Letztes Element - nth(): n-tes Element\n\ndf2 = pd.DataFrame({\n    \"Name\": [\"Alice\", \"Bob\", \"Mallory\", \"Mallory\", \"Bob\", \"Mallory\"],\n    \"Gender\": [\"f\", \"m\", \"f\", \"f\", \"m\", \"f\"],\n    \"YearOfBirth\": [1999, 1985, 1997, 1990, 1987, 1990],\n}\n)\ndf2[\"Age\"] = 2024 - df2[\"YearOfBirth\"]\ndf2.head()\n\n\n\n\n\n\n\n\nName\nGender\nYearOfBirth\nAge\n\n\n\n\n0\nAlice\nf\n1999\n25\n\n\n1\nBob\nm\n1985\n39\n\n\n2\nMallory\nf\n1997\n27\n\n\n3\nMallory\nf\n1990\n34\n\n\n4\nBob\nm\n1987\n37\n\n\n\n\n\n\n\n\ndf2_by_gender = df2.groupby(\"Gender\")\ndf2_by_gender\n\n&lt;pandas.core.groupby.generic.DataFrameGroupBy object at 0x7fa4cf1b2750&gt;\n\n\n\ndf2_by_gender[\"Age\"].mean()\n\nGender\nf    30.0\nm    38.0\nName: Age, dtype: float64",
    "crumbs": [
      "Einführung in Python",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Pandas</span>"
    ]
  },
  {
    "objectID": "01-Python/01-05-Pandas-Ex.html",
    "href": "01-Python/01-05-Pandas-Ex.html",
    "title": "6  Übung zu Pandas",
    "section": "",
    "text": "Für den Zweck der Buchhaltung in einem Unternehmen soll ein DataFrame erstellt werden, welches die folgenden Spalten enthält:\n\nPosition: Die Position im Unternehmen\nArbeitszeit: Die Arbeitszeit pro Woche\nLohn: Der wöchentliche Lohn in Euro\n\nDie Werte für die Position sollen aus der folgenden Liste entnommen werden:\nPosition: ['CEO', 'CFO', 'CTO', 'CIO', 'COO', 'CDO', 'CMO', 'CRO', 'CSO', 'CPO']\nArbeitszeit: [40, 40, 20, 40, 20, 40, 10, 40, 40, 60]\nGehalt: [10000, 8500, 2000, 3022, 1039, 2500, 3000, 1800, 20000, 10000]\n\n7 Aufgabe 1\n\nNennen Sie den DataFrame df und geben Sie ihn aus.\nGeben Sie die Spalte Position aus.\nGeben Sie die ersten 3 Zeilen des DataFrames aus.\nGeben Sie die letzten 3 Zeilen des DataFrames aus.\nGeben Sie die ersten 3 Zeilen der Spalte Position aus.\nGeben Sie die letzten 3 Zeilen der Spalte Position aus.\nGeben Sie die ersten 3 Zeilen der Spalten Position und Gehalt aus.\n\n\n\n8 Aufgabe 2\n\nBerechnen Sie den durchschnittlichen Gehalt im Unternehmen.\nBerechnen Sie den Stundenlohn für jede Personen im Unternehmen.\nBerechnen Sie den durchschnittlichen Stundenlohn im Unternehmen.\nBerechnen Sie den durchschnittlichen Stundenlohn für jede Position im Unternehmen.\nFinden Sie den niedrigsten Stundenlohn im Unternehmen.\nFinden Sie die Position mit dem niedrigsten Stundenlohn im Unternehmen.\nFinden Sie den höchsten Stundenlohn im Unternehmen.",
    "crumbs": [
      "Einführung in Python",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Übung zu Pandas</span>"
    ]
  },
  {
    "objectID": "02-Deskriptive-Statistik.html",
    "href": "02-Deskriptive-Statistik.html",
    "title": "7  Deskriptive Statistik",
    "section": "",
    "text": "7.1 Notation\nEine Variable ist eine Eigenschaft, die wir an einer Person, einem Objekt oder einem Ereignis messen können. In diesem Beispiel ist die Variable height die Größe einer Person. Im allgemeinen werden wir solche Variablen mit mit lateinischen Buchstaben bezeichnen, z.B. x, y, z. Was diese Bezeichnungen bedeuten, hängt vom Kontext ab. In diesem Beispiel sei x die Größe der Personen aus der Erhebung. Wir werden die Beobachtungen (hier Personen) üblicherweise mit einem Index bezeichnen: i = 1,2, \\ldots, n, wobei n die Anzahl der Beobachtungen ist. Die Werte der Variable x für die Beobachtungen i = 1,2, \\ldots, n bezeichnen wir mit x_1, x_2, \\ldots, x_n.\nZum Beispiel ist die Größe des zweiten Besuchers x_2 = 66 Inch.\n# Extract the height of the second customer\n# Remember that the index is 0-based, so the second customer has index 1\ncustomers[\"height\"][1]\n\n66\n# Extract the heights of the first three customers\n# Remember that indexing is exclusive, so the last index is not included\ncustomers[\"height\"][:3]\n\n0    74\n1    66\n2    64\nName: height, dtype: int64\n# Calculate the average height of the first three customers\ncustomers[\"height\"][:3].mean()\n\n68.0\nNun möchten wir den Mittelwert der Größe für alle Besucher berechnen.\nprint(customers[\"height\"].mean())\nprint(np.mean(customers[\"height\"]))\n\n66.56883259911895\n66.56883259911895",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Deskriptive Statistik</span>"
    ]
  },
  {
    "objectID": "02-Deskriptive-Statistik.html#notation",
    "href": "02-Deskriptive-Statistik.html#notation",
    "title": "7  Deskriptive Statistik",
    "section": "",
    "text": "Definition 7.1 (Stichprobenmittelwert (Sample Mean)) \n\\bar{x} = \\frac{1}{n} \\sum_{i=1}^{n} x_i\n\nDas ist einfach die Summe aller Werte geteilt durch die Anzahl der Werte.\n\n\\bar{x} = \\frac{x_1 + x_2 + \\ldots + x_n}{n}\n\n\n\nBeispiel 7.1 (Stichprobenmittelwert) Lasst uns den Mittelwert der ersten drei Besucher ausrechnen: x_1 = 74, x_2 = 66, x_3 = 64.\n\n\\frac{74 + 66 + 64}{3} = 68",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Deskriptive Statistik</span>"
    ]
  },
  {
    "objectID": "02-Deskriptive-Statistik.html#streuung",
    "href": "02-Deskriptive-Statistik.html#streuung",
    "title": "7  Deskriptive Statistik",
    "section": "7.2 Streuung",
    "text": "7.2 Streuung\nDer Mittelwert informiert uns über das Zentrum (Lage) der Daten. Die zweite Charakteristik einer Variable, die wir verstehen wollen, ist wie weit die Daten verteilt sind (wie unterschiedlich, heterogen, die Kunden in Bezug auf die Größe sind, zum Beispiel). Der Begriff der Streuung ist abstrakt und kann auf verschiedene Weisen gemessen werden. Wir können uns die Streuung zum Beispiel als die durchschnittliche Differenz der Kunden zum Mittelwert vorstellen. Dies ist das Konzept der Varianz.\n\nDefinition 7.2 (Stichprobenvarianz und Stichprobenstandardabweichung) Für eine Variable x mit n Beobachtungen: x_1, x_2, \\ldots, x_n, ist die Stichprobenvarianz definiert als:\n\nS_x^2 = \\frac{1}{n-1} \\sum_{i=1}^{n} (x_i - \\bar{x})^2\n\nDabei ist \\bar{x} der Stichprobenmittelwert.\nDie Stichprobenstandardabweichung ist die Quadratwurzel der Stichprobenvarianz:\n\nS_x = \\sqrt{S^2}\n\n\n\nBeispiel 7.2 (Stichprobenvarianz und Stichprobenstandardabweichung) Lasst uns die Stichprobenstandardabweichung für die ersten drei Besucher berechnen x_1 = 74, x_2 = 66, x_3 = 64.\nZuerst müssen wir den Stichprobenmittelwert ausrechnen: \\bar{x} = 68 (Beispiel 7.1)\nDanach berechnen wir die Differenzen der Werte zum Mittelwert und quadrieren diese:\n\nS^2 = \\frac{(74 - 68)^2 + (66 - 68)^2 + (64 - 68)^2}{3-1} = \\frac{36 + 4 + 16}{2} = 28\n\nDie Stichprobenstandardabweichung ist die Quadratwurzel der Stichprobenvarianz:\n\nS = \\sqrt{28} \\approx 5.29\n\n\n\n# Hier replizieren wir die Berechnung der Varianz der Größe der ersten drei Kunden\ncustomers[\"height\"][0:3].var()\n\n28.0\n\n\n\n# Sie können die Varianz auch mit der numpy Funktion np.var berechnen\n\nnp.var(customers[\"height\"][0:3])\n\n18.666666666666668\n\n\n\nnp.var(customers[\"height\"][0:3], ddof=1)\n\n28.0\n\n\n\n# Die Standardabweichung der Größe der ersten drei Besucher berechnen\n\ncustomers[\"height\"][0:3].std()\n\n5.291502622129181\n\n\n\nnp.std(customers[\"height\"][0:3], ddof=1)\n\n5.291502622129181\n\n\nnp.var und np.std berechnen die Stichprobenvarianz und -standardabweichung nach der Formel\n\nS^2 = \\frac{1}{1 - \\text{ddof}} \\sum_{i=1}^{n} (x_i - \\bar{x})^2\n\nwobei ddof die Anzahl der Freiheitsgrade im Nenner (denominator degrees of freedom) steht. Die Voreinstellung ist ddof=0.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Deskriptive Statistik</span>"
    ]
  },
  {
    "objectID": "02-Deskriptive-Statistik.html#weitere-maße-der-lage-und-streuung",
    "href": "02-Deskriptive-Statistik.html#weitere-maße-der-lage-und-streuung",
    "title": "7  Deskriptive Statistik",
    "section": "7.3 Weitere Maße der Lage und Streuung",
    "text": "7.3 Weitere Maße der Lage und Streuung\nDie Reduzierung auf einen einzigen Wert als Stichprobenmittelwert ist sehr nützlich, weil wir leicht darüber nachdenken können (nur ein Wert). Allerdings ignoriert diese Reduktion viele Details über die Kunden. Zum Beispiel wissen wir nicht, wie viele Kunden nahe am Mittelwert sind, wie viele weit entfernt sind, und so weiter. Die Standardabweichung hilft uns, dies zu verstehen, ist aber immer noch eine einzige Zahl.\nUm unser Verständnis der Daten weiter zu vertiefen, können wir andere Maße der Lage und Streuung verwenden.\n\nDer Median ist der Wert, der die Daten in zwei gleiche Hälften teilt. Es ist der Wert, der die gleiche Anzahl von Beobachtungen über und unter sich hat. Sie können sagen, dass etwa die Hälfte der Beobachtungen einen Wert kleiner als den Median hat und etwa die andere Hälfte einen Wert größer als den Median hat. Ein anderer Name für den Median ist das zweite Quartil (Q2). Dies kommt daher, dass die Stichprobe in vier Teile geteilt wird. Ein weiterer Name für den Median ist das 50. Perzentil (Teilung der Stichprobe in 100 Teile) oder das 0,5-Quantil.\nDas erste Quartil (Q1) ist der Wert, der die ersten 25% der Daten von den restlichen trennt. Sie können sagen, dass ungefähr 25% der Beobachtungen einen Wert kleiner als Q1 und 75% einen Wert größer als Q1 haben. Ein anderer Name für das erste Quartil ist das 25. Perzentil oder das 0,25-Quantil.\nDas zweite Quartil (Q2) ist der Median.\nDas dritte Quartil (Q3) ist der Wert, der die ersten 75% der Daten von den restlichen trennt. Sie können sagen, dass ungefähr 75% der Beobachtungen einen Wert kleiner als Q3 und 25% einen Wert größer als Q3 haben. Ein anderer Name für das dritte Quartil ist das 75. Perzentil oder das 0,75-Quantil.\nDas Maximum ist der größte Wert in den Daten. Es wird manchmal das 100. Perzentil genannt.\nDas Minimum ist der kleinste Wert in den Daten. Es wird manchmal das 0. Perzentil genannt.\n\nDie Differenz zwischen dem Minimum und dem Maximum ist der Bereich (range) der Daten. Es ist ein Maß für die Streuung der Daten, aber es ist sehr anfällig für extreme Werte. Ein Ausreißer ist ein Wert, der sehr weit von den anderen Werten entfernt ist. Der Median und die Quartile sind weniger anfällig für Ausreißer und werden als robuste Maße der Lage und Streuung bezeichnet.\nDie Differenz zwischen dem dritten und dem ersten Quartil ist der Interquartilsabstand (IQR). Es ist ein Maß für die Streuung der mittleren 50% der Daten. Es ist auch ein robustes Maß der Streuung, da es weniger anfällig für Ausreißer ist.\n\n# Mittelwert, Standardabweichung, Minimum und Maximum und die Quartile der Größe der Kunden berechnen\n\ncustomers[\"height\"].describe()\n\ncount    1816.000000\nmean       66.568833\nstd         3.831822\nmin        57.000000\n25%        64.000000\n50%        66.000000\n75%        69.250000\nmax        82.000000\nName: height, dtype: float64\n\n\n\n# Falls wir nur eine der statistischen Kennzahlen berechnen wollen, können wir auch die entsprechende Funktion verwenden\n\nprint(customers[\"height\"].min())\nprint(customers[\"height\"].quantile(0.25))\nprint(customers[\"height\"].quantile(0.5))\nprint(customers[\"height\"].quantile(0.75))\nprint(customers[\"height\"].max())\n\n57\n64.0\n66.0\n69.25\n82\n\n\n\n# Den Interquartilsabstand berechnen\n\ncustomers[\"height\"].quantile(0.75) - customers[\"height\"].quantile(0.25)\n\n5.25\n\n\nBerechnen Sie den Mittelwert, Median, Standardabweichung, Minimum, Maximum, Quartile und Interquartilsabstand für das Gewicht der Kunden.\n\n# Schreiben Sie Ihren Code hier\n\nHäufig werden diese Quantile und der Interquartilsabstand in einem Boxplot dargestellt. Ein Boxplot ist ein Diagramm, das die Verteilung der Daten in einem Box-Whisker-Diagramm darstellt. Die Box repräsentiert das Interquartilsintervall (IQR). Die Whisker repräsentieren die Daten außerhalb des IQR. Punkte, die außerhalb der Whisker liegen sind Punkte, die weit von den anderen Daten entfernt sind und werden Ausreißer genannt (was ein Ausreißer ist, ist allerdings kompliziert).\n\nsns.boxplot(customers[\"height\"], orient=\"h\")\n\n\n\n\n\n\n\n\nDie Boxplots sind nützlich, wenn wir die Verteilung einer Variablen in verschiedenen Gruppen vergleichen wollen. Als Beispiel können wir die Verteilung der Größe in verschiedenen ethnischen Gruppen vergleichen.\n\nsns.boxplot(x = customers[\"height\"], y = customers[\"ethnicity\"])",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Deskriptive Statistik</span>"
    ]
  },
  {
    "objectID": "02-Deskriptive-Statistik.html#zusammenfassung-kategorialer-variablen",
    "href": "02-Deskriptive-Statistik.html#zusammenfassung-kategorialer-variablen",
    "title": "7  Deskriptive Statistik",
    "section": "7.4 Zusammenfassung kategorialer Variablen",
    "text": "7.4 Zusammenfassung kategorialer Variablen\nDer Mittelwert und die Standardabweichung machen nur für Variablen Sinn, für die Addition und Multiplikation sinnvoll sind. Insbesondere machen sie keinen Sinn für kategoriale Variablen, z. B. die Ethnie der Kunden.\nDie wichtigste Zusammenfassung für kategoriale Variablen ist die Häufigkeitstabelle. Eine Häufigkeitstabelle zeigt die Anzahl der Beobachtungen für jede Kategorie. Die relative Häufigkeitstabelle zeigt den Anteil der Beobachtungen für jede Kategorie.\n\ncustomers[\"ethnicity\"].value_counts()\n\nethnicity\nWhite       1494\nBlack        180\nHispanic     104\nOther         38\nName: count, dtype: int64\n\n\n\nsns.countplot(data = customers, x=\"ethnicity\")",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Deskriptive Statistik</span>"
    ]
  },
  {
    "objectID": "02-Deskriptive-Statistik.html#datentransformationen",
    "href": "02-Deskriptive-Statistik.html#datentransformationen",
    "title": "7  Deskriptive Statistik",
    "section": "7.5 Datentransformationen",
    "text": "7.5 Datentransformationen\nEs ist in fast jeder Analyse notwendig, die Daten zu transformieren. Als Beispiel können wir die Größe in Inch in Zentimeter umrechnen. Die Umrechnung von Inch in Zentimeter erfolgt durch Multiplikation mit 2,54. Die Umrechnung von Pfund in Kilogramm erfolgt durch Multiplikation mit 0,45.\n\n# Hier erstellen wir eine neue Spalte, die die Größe in cm enthält\ncustomers[\"height_cm\"] = customers[\"height\"] * 2.54\n\n\n# Erstellen Sie eine neue Spalte \"weight_kg\" in dem Dataframe \"customers\", die die Werte der Spalte \"weight\" in Kilogramm umrechnet.\n# 1 Pfund entspricht 0.453592 Kilogramm.\n\nHäufig möchten wir eine stetige Variable in Kategorien einteilen. Zum Beispiel möchten wir eine Variable erstellen, die angibt, ob eine Person jünger als 30 Jahre ist oder nicht. Dies ist eine binäre Variable, die wir aus einer kontinuierlichen Variable erstellen.\n\ncustomers[\"is_under_30\"] = customers[\"age\"] &lt; 30\ncustomers[\"is_under_30\"].head()\n\n0    False\n1    False\n2     True\n3    False\n4    False\nName: is_under_30, dtype: bool\n\n\nFalls wir mehr als zwei Kategorien brauchen, bietet die Funktion pd.cut die Möglichkeit, die Daten in Kategorien einzuteilen.\n\n# Wir lassen uns die Häufigkeitsverteilung der Altersgruppen ausgeben,\n# um zu sehen, wie pd.cut funktioniert\n\npd.cut(\n    customers[\"age\"],\n    bins=[0, 30, 64, np.inf],\n).value_counts()\n\nage\n(30.0, 64.0]    1041\n(0.0, 30.0]      512\n(64.0, inf]      263\nName: count, dtype: int64\n\n\n\n# Hier weisen wir Etiketten der Kategorien und speichern das Ergebnis in einer neuen Spalte \"age_group\"\n\ncustomers[\"age_group\"] = pd.cut(\n    customers[\"age\"],\n    bins=[0, 30, 64, np.inf],\n    labels=[\"&lt;30\", \"30-64\", \"65+\"]\n)\n\n# Als Kontrolle lassen wir uns die ersten 5 Zeilen des Dataframes anzeigen\ncustomers[[\"age\", \"age_group\"]].head()\n\n\n\n\n\n\n\n\nage\nage_group\n\n\n\n\n0\n45\n30-64\n\n\n1\n58\n30-64\n\n\n2\n29\n&lt;30\n\n\n3\n57\n30-64\n\n\n4\n91\n65+",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Deskriptive Statistik</span>"
    ]
  },
  {
    "objectID": "02-Deskriptive-Statistik.html#aufgabe",
    "href": "02-Deskriptive-Statistik.html#aufgabe",
    "title": "7  Deskriptive Statistik",
    "section": "7.6 Aufgabe",
    "text": "7.6 Aufgabe\nBerechnen Sie den BMI (Body Mass Index) für die Kunden. Der BMI ist definiert als das Körpergewicht in Kilogramm geteilt durch das Quadrat der Größe in Metern. Das Gewicht muss in Kilogramm und die Größe in Metern sein.\n\n# Erstellen Sie die Spalte \"bmi\" in dem Dataframe \"customers\", die den Body Mass Index berechnet.\n\ncustomers[\"bmi\"] = customers[\"weight\"] / (customers[\"height\"] / 100) ** 2\n\nDie Referenzwerte für den BMI sind:\n\nUnter 18,5: Untergewicht\n18,5 - 24,9: Normalgewicht\n25 - 29,9: Übergewicht\n30 oder mehr: Adipositas\nEin Verkäufer behauptet, daß die Kunden im Einkaufszentrum im Durchschnitt übergewichtig sind. Überprüfen Sie diese Behauptung anhand der Daten.\nEin anderer Verkäufer behauptet, daß mehr als ein Viertel der Besucher im Einkaufszentrum adipös sind. Überprüfen Sie diese Behauptung anhand der Daten.\n\n\n# Berechnen Sie den durchschnittlichen BMI\n\ncustomers[\"bmi\"].mean()\n\n351.1234041165582\n\n\n\n# Lassen Sie sich die Beschreibung der Spalte \"bmi\" anzeigen. (Tipp: Verwenden Sie die Methode .describe() der Spalte \"bmi\").\n\ncustomers[\"bmi\"].describe()\n\ncount    1789.000000\nmean      351.123404\nstd        65.866606\nmin       163.265306\n25%       307.478675\n50%       340.136054\n75%       378.703497\nmax       761.862330\nName: bmi, dtype: float64\n\n\nErstellen Sie eine neue Spalte is_underweight in der Tabelle customers, die angibt, ob ein Kunde untergewichtig ist oder nicht. Erstellen Sie eine weitere Spalte is_normal in der Tabelle customers, die angibt, ob ein Kunde ein Normalgewicht hat oder nicht.\nHinweis: Sie können diese Variable mit den logischen Operatoren &lt;, &lt;=, &gt;, &gt;= und == erstellen. Logische Operationen können Sie mit den Operatoren & (und), | (oder) und ~ (nicht) verknüpfen (Hinweis: hier brauchen Sie und).\n\n# Erstellen Sie die zwei Variablen hier\n\ncustomers[\"is_overweight\"] = customers[\"bmi\"] &gt; 25\n\nWie viele Kunden sind untergewichtig? Wie viele Kunden haben ein Normalgewicht? Hinweis: Benutzen Sie die Methode value_counts um die Anzahl der Kunden in jeder Kategorie zu berechnen. Sie können auch die Methode sum benutzen, um die Anzahl der Kunden in einer Kategorie zu berechnen.\n\n# Wie viele Kunden sind untergewichtig?\n# a) mit .value_counts()\n\n# b) mit .sum()\n\nErstellen Sie eine neue Spalte bmi_category in der Tabelle customers, die die Kategorie des BMI angibt (Untergewicht, Normalgewicht, Übergewicht, Adipositas). Hinweis: Sie können diese Variable mit der Funktion pd.cut erstellen.\n\n# Erstellen Sie `bmi_category` hier\n\nVisualisieren Sie die Verteilung der Kategorien des BMI. Hinweis: Benutzen Sie die Funktion sns.countplot aus der Bibliothek seaborn.\n\n# Erstellen Sie die Graphik hier\n\nNun möchten Wir die Verteilung des BMI für Männer und Frauen vergleichen. Berechnen Sie den Mittelwert des BMI für Männer und Frauen. Hinweis: Sie können die Methode groupby benutzen, um die Mittelwerte für verschiedene Gruppen zu berechnen.\n\n# Als Beispiel für die Benutzung von .groupby() werden hier die Mittelwerte des Alters für jede Ethnie berechnet\n\ncustomers.groupby(\"ethnicity\")[\"age\"].mean()\n\nethnicity\nBlack       41.733333\nHispanic    36.288462\nOther       41.763158\nWhite       43.571620\nName: age, dtype: float64\n\n\n\n# Berechnen Sie die Mittelwerte des BMI für Männer und Frauen.\n\n\n# Vergleichen Sie die Verteilungen des BMI für Männer und Frauen mit einem Boxplot.\n\n# Bevor wir die Boxplots erstellen, müssen wir die Variable \"male\" in eine kategorische Variable umwandeln. Die neue Variable nenne wir \"sex\"\ncustomers[\"sex\"] = pd.Categorical(customers[\"male\"], ordered=False)\n\n# Erstellen Sie die Boxplots hier",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Deskriptive Statistik</span>"
    ]
  },
  {
    "objectID": "03-KQ-Methode.html",
    "href": "03-KQ-Methode.html",
    "title": "8  Die KQ-Methode",
    "section": "",
    "text": "8.1 KQ-Methode im Modell nur mit einer Konstante\nZuerst werden wir das Problem in einem sehr einfachen Fall betrachten. Betrachten wir die Prognosegleichung\n\\hat{y} = \\hat{\\beta}_0\nDie Prognose ist für alle Werte von x gleich \\hat{\\beta}_0 (d.h. die Prognose ist eine horizontale Gerade). Wo sollten wir diese horizontale Gerade zeichnen, um die Residuenquadratsumme zu minimieren?\nFür die Gleichung oben ist die Residuenquadratsumme:\n\\text{RSS}(\\hat{\\beta}_0) = \\sum_{i=1}^{n} (y_i - \\hat{\\beta}_0)^2\nIn Abbildung 8.5 ist die RSS für mehrere Werte von \\hat{\\beta}_0 zwischen 1.1 und 3.1 dargestellt.\nCode\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots()\n\nbeta0 = np.linspace(2.1 - 1, 2.1 + 1, 100)\nrss_beta0 = np.zeros_like(beta0)\n\nfor i in range(len(beta0)):    \n    res = invoices['Time'] - beta0[i]\n    rss_beta0[i] = np.sum(res**2)\n\nax.plot(beta0, rss_beta0)\nax.set_xlabel(r\"$\\hat{\\beta}_0$\")\nax.set_ylabel(r\"$RSS(\\hat{\\beta}_0)$\")\n\n\n\n\n\n\n\nText(0, 0.5, '$RSS(\\\\hat{\\\\beta}_0)$')\n\n\n(a) r”RSS für verschiedene Werte \\hat{\\beta}_0 im Modell \\widehat{Time} = \\hat{\\beta}_0.”\n\n\n\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\n\nAbbildung 8.5",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Die KQ-Methode</span>"
    ]
  },
  {
    "objectID": "03-KQ-Methode.html#kq-methode-im-modell-nur-mit-einer-konstante",
    "href": "03-KQ-Methode.html#kq-methode-im-modell-nur-mit-einer-konstante",
    "title": "8  Die KQ-Methode",
    "section": "",
    "text": "Übungsaufgabe 8.3 (Das Modell nur mit einer Konstante) Leiten Sie den Wert von \\hat{\\beta}_0 her, der die Residuenquadratsumme minimiert.\n\n\n\n\n\n\n\nBeweis\n\n\n\n\n\nWir fangen mit der ersten Ableitung der Residuenquadratsumme nach \\hat{\\beta}_0 an.\n\n\\begin{align*}\n\\frac{\\partial}{\\partial \\hat{\\beta}_0} RSS(\\hat{\\beta}_0) & =\n\\sum_{i=1}^n 2(y_i - \\hat{\\beta}_0) \\cdot (-1) \\\\\n& = -2 \\sum_{i=1}^n (y_i - \\hat{\\beta}_0) \\\\\n& = -2 \\sum_{i=1}^n y_i + 2 \\sum_{i=1}^n \\hat{\\beta}_0 \\\\\n& = -2 \\sum_{i=1}^n y_i + 2 n \\hat{\\beta}_0\n\\end{align*}\n\nDie notwendige Bedingung für ein Extremum (Minimum oder Maximum) ist, daß die erste Ableitung gleich Null ist.\n\n\\begin{align*}\n-2 \\sum_{i=1}^n y_i + 2 n \\hat{\\beta}_0 & = 0 \\\\\n\\hat{\\beta}_0 & = \\frac{1}{n} \\sum_{i=1}^n y_i \\\\\n& = \\overline{y}\n\\end{align*}\n\nDer optimale Wert von \\hat{\\beta}_0, der die Residuenquadratsumme minimiert, ist einfach der Durchschnitt der beobachteten Werte.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Die KQ-Methode</span>"
    ]
  },
  {
    "objectID": "03-KQ-Methode.html#das-modell-mit-einer-variable-ohne-konstante",
    "href": "03-KQ-Methode.html#das-modell-mit-einer-variable-ohne-konstante",
    "title": "8  Die KQ-Methode",
    "section": "8.2 Das Modell mit einer Variable ohne Konstante",
    "text": "8.2 Das Modell mit einer Variable ohne Konstante\nLasst uns jetzt das Modell mit einer Variable betrachten, aber ohne Konstante. Die Prognosegleichung ist\n\n\\hat{y} = \\hat{\\beta}_1 x\n\nLeiten Sie den Wert von \\hat{\\beta}_1 her, der die Residuenquadratsumme minimiert.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Die KQ-Methode</span>"
    ]
  },
  {
    "objectID": "03-KQ-Methode.html#herleitung",
    "href": "03-KQ-Methode.html#herleitung",
    "title": "8  Die KQ-Methode",
    "section": "8.3 Herleitung",
    "text": "8.3 Herleitung\nWir fangen mit der ersten Ableitung der Residuenquadratsumme nach \\hat{\\beta}_1 an.\n\n\\begin{align*}\n\\frac{\\partial}{\\partial \\hat{\\beta}_1} RSS(\\hat{\\beta}_1) & =\n\\sum_{i=1}^n 2(y_i - \\hat{\\beta}_1 x_i) \\cdot (-x_i) \\\\\n& = -2 \\sum_{i=1}^n x_i y_i + 2 \\hat{\\beta}_1 \\sum_{i=1}^n x_i^2\n\\end{align*}\n\nDie notwendige Bedingung für ein Extremum (Minimum oder Maximum) ist, daß die erste Ableitung gleich Null ist.\n\n\\begin{align*}\n-2 \\sum_{i=1}^n x_i y_i + 2 \\hat{\\beta}_1 \\sum_{i=1}^n x_i^2 & = 0 \\\\\n\\hat{\\beta}_1 \\sum_{i=1}^n x_i^2 & = \\sum_{i=1}^n x_i y_i \\\\\n\\hat{\\beta}_1 & = \\frac{\\sum_{i=1}^n x_i y_i}{\\sum_{i=1}^n x_i^2} \\\\\n& = \\frac{\\frac{1}{n}\\sum_{i=1}^n x_i y_i}{\\frac{1}{n}\\sum_{i=1}^n x_i^2} \\\\\n& = \\frac{\\overline{x y}}{\\overline{x^2}}\n\\end{align*}",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Die KQ-Methode</span>"
    ]
  },
  {
    "objectID": "03-KQ-Methode.html#das-modell-mit-einer-variable-und-einer-konstante",
    "href": "03-KQ-Methode.html#das-modell-mit-einer-variable-und-einer-konstante",
    "title": "8  Die KQ-Methode",
    "section": "8.4 Das Modell mit einer Variable und einer Konstante",
    "text": "8.4 Das Modell mit einer Variable und einer Konstante\nIm Modell mit einer Konstante und einem Predictor ist die Prognosegleichung \n\\hat{y} = \\hat{\\beta}_0 + \\hat{\\beta}_1 x\n\nDie RSS ist\n\n\\begin{align*}\n\\text{RSS}(\\hat{\\beta}_0, \\hat{\\beta}_1) & = \\sum_{i=1}^n (y_i - \\hat{y}_i)^2 \\\\\n  & = \\sum_{i=1}^n (y_i - \\hat{\\beta}_0 - \\hat{\\beta}_1 x_i)^2\n\\end{align*}\n\nDie notwendige Bedingung für ein Extremum (Minimum oder Maximum) ist, dass die erste Ableitung gleich Null ist.\n\n\\begin{align*}\n\\frac{\\partial}{\\partial \\hat{\\beta}_0} \\text{RSS}(\\hat{\\beta}_0, \\hat{\\beta}_1) & = -2 \\sum_{i=1}^n (y_i - \\hat{\\beta}_0 - \\hat{\\beta}_1 x_i) = 0 \\\\\n\\frac{\\partial}{\\partial \\hat{\\beta}_1} \\text{RSS}(\\hat{\\beta}_0, \\hat{\\beta}_1) & = -2 \\sum_{i=1}^n (y_i - \\hat{\\beta}_0 - \\hat{\\beta}_1 x_i) x_i = 0\n\\end{align*}\n\nAus der ersten Gleichung erhalten wir\n\n\\begin{align*}\n\\sum_{i=1}^n y_i - \\hat{\\beta}_0 n - \\hat{\\beta}_1 \\sum_{i=1}^n x_i & = 0 \\\\\n\\hat{\\beta}_0 n + \\hat{\\beta}_1 \\sum_{i=1}^n x_i & = \\sum_{i=1}^n y_i \\\\\n\\hat{\\beta}_0 & = \\overline{y} - \\hat{\\beta}_1 \\overline{x}\n\\end{align*}\n\nDie zweite Gleichung ergibt\n\n\\begin{align*}\n\\sum_{i=1}^n y_i x_i - \\hat{\\beta}_0 \\sum_{i=1}^n x_i - \\hat{\\beta}_1 \\sum_{i=1}^n x_i^2 & = 0 \\\\\n\\hat{\\beta}_0 \\sum_{i=1}^n x_i + \\hat{\\beta}_1 \\sum_{i=1}^n x_i^2 & = \\sum_{i=1}^n y_i x_i \\\\\n\\hat{\\beta}_0 & = \\overline{y} - \\hat{\\beta}_1 \\overline{x}\n\\end{align*}\n\nWir setzen für \\hat{\\beta}_0 in die zweite Gleichung ein und erhalten\n\n\\begin{align*}\n(\\overline{y} - \\hat{\\beta}_1 \\overline{x}) \\sum_{i=1}^n x_i + \\hat{\\beta}_1 \\sum_{i=1}^n x_i^2 & = \\sum_{i=1}^n y_i x_i \\\\\n\\overline{y} \\sum_{i=1}^n x_i - \\hat{\\beta}_1 \\overline{x} \\sum_{i=1}^n x_i + \\hat{\\beta}_1 \\sum_{i=1}^n x_i^2 & = \\sum_{i=1}^n y_i x_i \\\\\n\\hat{\\beta}_1 \\sum_{i=1}^n x_i^2 & = \\sum_{i=1}^n y_i x_i - \\overline{y} \\sum_{i=1}^n x_i + \\hat{\\beta}_1 \\overline{x} \\sum_{i=1}^n x_i \\\\\n\\hat{\\beta}_1 & = \\frac{\\sum_{i=1}^n y_i x_i - \\overline{y} \\sum_{i=1}^n x_i}{\\sum_{i=1}^n x_i^2 - \\overline{x} \\sum_{i=1}^n x_i}\n\\end{align*}\n\nNun können wir die Ausdrücke vereinfachen und erhalten\n\n\\begin{align*}\n\\hat{\\beta}_1 & = \\frac{\\overline{x y} - \\overline{x} \\cdot \\overline{y}}{\\overline{x^2} - \\overline{x}^2} \\\\\n\\hat{\\beta}_0 & = \\overline{y} - \\hat{\\beta}_1 \\overline{x}\n\\end{align*}\n\nThe last expression may seem a bit complicated, but it is actually quite simple. It is just the ratio between the empirical covariance between x_i and y_i divided by the variance of x_i.\nThe empirical covariance between x_i and y_i is defined as the sum of the products of the deviations of x_i and y_i from their respective means, divided by the number of observations.\n\nDefinition 8.1 (Empirische Kovarianz) Die empirische Kovarianz zwischen zwei Variablen x und y mit n Werten ist definiert als\n\nS_{xy} = \\frac{1}{n - 1} \\sum_{i=1}^n (x_i - \\overline{x})(y_i - \\overline{y})\n\n\n\nTheorem 8.1 (Alternative Formel für die Kovarianz) Die Kovarianz definiert in Definition 8.1 lässt sich auch darstellen als\n\n(n - 1) S_{xy} = n(\\overline{x y} - \\overline{x} \\overline{y})\n\n\n\n\n\n\n\n\nBeweis\n\n\n\n\n\nDer Beweis folgt den gleichen Schritten wie der Beweis für die alternative Darstellung der empirischen Varianz.\n\n\\begin{align*}\n(n - 1) S_{xy} & = \\sum_{i=1}^n (x_i - \\overline{x})(y_i - \\overline{y}) \\\\\n& = \\sum_{i=1}^n x_i y_i - \\overline{x} \\sum_{i=1}^n y_i - \\overline{y} \\sum_{i=1}^n x_i + n \\overline{x} \\overline{y} \\\\\n& = n(\\overline{x y} - \\overline{x} \\overline{y})\n\\end{align*}\n\n\n\n\n\nTheorem 8.2 (Alternative Varianzformel) Wir haben bereits die empirische Kovarianz definiert als\n\nS_x^2 = \\frac{1}{n - 1} \\sum_{i=1}^n (x_i - \\overline{x})^2\n\nWir können zeigen, dass die folgende Darstellung für die empirische Varianz gilt\n\nS_x^2 = \\frac{n}{n  - 1}(\\overline{x_i^2} - \\overline{x}^2)\n\n\n\n\n\n\n\n\nBeweis\n\n\n\n\n\nWir benutzen die Definition der Varianz und die Definition des Mittelwertes.\n\n\\begin{align*}\n(n - 1) S_x^2 & =  \\sum_{i=1}^n (x_i - \\overline{x})^2 \\\\\n& =  \\sum_{i=1}^n (x_i^2 - 2x_i \\overline{x} + \\overline{x}^2) \\\\\n& =  \\sum_{i=1}^n x_i^2 - 2\\overline{x} \\sum_{i=1}^n x_i + \\overline{x}^2 \\sum_{i=1}^n 1 \\\\\n& =  \\sum_{i=1}^n x_i^2 - 2\\overline{x} \\sum_{i=1}^n x_i + \\overline{x}^2 n \\\\\n& =  \\sum_{i=1}^n x_i^2 - 2\\overline{x}^2 n + \\overline{x}^2 n \\\\\n& =  \\sum_{i=1}^n x_i^2 - n \\overline{x}^2 \\\\\n& = n (\\overline{x^2} - \\overline{x}^2)\n\\end{align*}\n\n\n\n\n\n# Set seed for reproducibility\nnp.random.seed(0)\n\n# Create a DataFrame\nx = np.random.normal(size=100, loc=0, scale=1)\ny = 2 * x + np.random.normal(size=100, scale=1)\n\nprod_pos = (x &gt; x.mean()) * (y &gt; y.mean()) + (x &lt;= x.mean()) * (y &lt;= y.mean())\nprod_neg = np.logical_not(prod_pos)\n\n# Plot\nplt.scatter(x[prod_pos], y[prod_pos], color=\"black\")\nplt.scatter(x[prod_neg], y[prod_neg], color=\"red\")\n\nplt.axvline(x.mean(), color='firebrick', label='Mittelwert von x')\nplt.axhline(y.mean(), color='steelblue', label='Mittelwert von y')\n\n\n\n\n\n\n\nAbbildung 8.6: Streudiagramm mit positiver Kovarianz\n\n\n\n\n\nDie rote Linie ist bei dem Durchschnitt der x-Werte gezeichnet und die blaue Linie ist bei dem Durchschnitt der y-Werte gezeichnet. Die Kovarianz misst das durchschnittliche Produkt der Abweichungen der x-Werte von ihrem Durchschnitt und der y-Werte von ihrem Durchschnitt. Das Produkt ist positiv, wenn die x-Werte und die y-Werte gleichzeitig über oder unter ihren Durchschnitten liegen. Das Produkt ist negativ, wenn die x-Werte über ihrem Durchschnitt liegen, während die y-Werte unter ihrem Durchschnitt liegen, oder umgekehrt.\n\n# Kovarianz von zwei NumPy-Arrays\n# Achten Sie darauf, dass eine ganze Kovarianzmatrix zurückgegeben wird.\n# Die Diagonalelemente sind die Varianzen der einzelnen Arrays.\n\nnp.cov(x, y)\n\narray([[1.02608749, 2.16986562],\n       [2.16986562, 5.65646178]])\n\n\n\nnp.var(x, ddof=1)\n\n1.0260874941564961\n\n\n\nnp.var(y, ddof=1)\n\n5.656461778144082\n\n\nNur das Vorzeichen der Kovarianz ist wichtig. Die Größe der Kovarianz hängt von den Einheiten der Variablen ab. Um die Kovarianz dimensionslos zu machen, können wir sie durch das Produkt der Standardabweichungen der beiden Variablen teilen. Das gibt uns den Korrelationskoeffizienten.\n\nnp.cov(x, 20 * y)\n\narray([[1.02608749e+00, 4.33973123e+01],\n       [4.33973123e+01, 2.26258471e+03]])\n\n\nLasst uns auch ein Beispiel betrachten, wo die Kovarianz negativ ist. In dem folgenden Code ändern wir nur das Vorzeichen des Koeffizienten von x in der Gleichung von y.\n\n\nCode\n# Set seed for reproducibility\nnp.random.seed(23)\n\n# Create a DataFrame\nx1 = np.random.normal(size=100, loc=0, scale=1)\ny1 = - 2 * x1 + np.random.normal(size=100, scale=1)\n\n# Plot\nplt.scatter(x1, y1, color=\"black\")\nplt.axvline(x1.mean(), color='firebrick', label='Mittelwert von x')\nplt.axhline(y1.mean(), color='steelblue', label='Mittelwert von y')\n\n\n\n\n\n\n\n\nAbbildung 8.7: Streudiagramm von x und y mit negativer Kovarianz.\n\n\n\n\n\n\nnp.cov(x1, y1)\n\narray([[ 0.90312011, -1.81047309],\n       [-1.81047309,  4.67610569]])\n\n\n\nx_rand = np.random.uniform(size=100)\ny_rand = np.random.uniform(size=100)\n\nfig, ax = plt.subplots()\nax.scatter(x_rand, y_rand, color=\"black\")\n\nax.axvline(x_rand.mean(), color='firebrick', label='Mittelwert von x')\nax.axhline(y_rand.mean(), color='steelblue', label='Mittelwert von y')\n\n\n\n\n\n\n\nAbbildung 8.8: Streudiagramm von x und y mit unabhängigen Variablen.\n\n\n\n\n\n\nnp.cov(x_rand, y_rand)\n\narray([[ 0.08527383, -0.01966643],\n       [-0.01966643,  0.07947542]])\n\n\n\nnp.corrcoef(x_rand, y_rand)\n\narray([[ 1.        , -0.23889178],\n       [-0.23889178,  1.        ]])\n\n\n\nDefinition 8.2 (Korrelationskoeffizient) Der empirische Korrelationskoeffizient zwischen zwei Variablen x und y mit n Werten ist definiert als\n\nr_{xy} = \\frac{S_{xy}}{S_x S_y}\n\ndabei ist S_{xy} die Kovarianz zwischen x und y, und S_x und S_y sind die Standardabweichungen von x und y.\n\nWeil die Kovarianz durch das Produkt der Standardabweichungen geteilt wird, ist der Korrelationskoeffizient dimensionslos. Außerdem ist der Korrelationskoeffizient immer zwischen -1 und 1. Ein Korrelationskoeffizient von 1 bedeutet, dass die beiden Variablen auf einer Geraden mit positiver Steigung liegen. Ein Korrelationskoeffizient von -1 bedeutet, dass die beiden Variablen auf einer Geraden mit negativer Steigung liegen. Ein Korrelationskoeffizient von 0 bedeutet, dass es keine lineare Assoziation zwischen den beiden Variablen gibt.\nZusammengefasst:\n\n-1 \\leq r_{xy} \\leq 1\n\n\ny = a + b x \\implies r_{xy} = 1, \\quad b &gt; 0\n\n\ny = a - b x \\implies r_{xy} = -1, \\quad b &gt; 0\n\n\n\n\n\n\n\nWieso ist der Korrelationskoeffizient immer zwischen -1 und 1?\n\n\n\n\n\nFür den Beweis werden wir zuerst zeigen, dass sich die Skalierungsfaktoren 1 / (n - 1) im Zähler und im Nenner der Definition des Korrelationskoeffizienten kürzen.\n\n\\begin{align*}\nr_{xy} & = \\frac{S_{xy}}{S_x S_y} \\\\\n    & = \\frac{\\frac{1}{n-1} \\sum_{i=1}^n (x_i - \\overline{x})(y_i - \\overline{y})}{\\sqrt{\\frac{1}{n-1} \\sum_{i=1}^n (x_i - \\overline{x})^2} \\sqrt{\\frac{1}{n-1} \\sum_{i=1}^n (y_i - \\overline{y})^2}} \\\\\n    & = \\frac{\\frac{1}{n - 1}}{\\frac{1}{n - 1}}\\frac{\\sum_{i=1}^n (x_i - \\overline{x})(y_i - \\overline{y})}{\\sqrt{\\sum_{i=1}^n (x_i - \\overline{x})^2} \\sqrt{\\sum_{i=1}^n (y_i - \\overline{y})^2}} \\\\\n    & = \\frac{\\sum_{i=1}^n (x_i - \\overline{x})(y_i - \\overline{y})}{\\sqrt{\\sum_{i=1}^n (x_i - \\overline{x})^2} \\sqrt{\\sum_{i=1}^n (y_i - \\overline{y})^2}}\n\\end{align*}\n\nFür den Beweis brauchen wir zuerst die Cauchy-Schwarz-Ungleichung. Diese Ungleichung besagt, dass das Quadrat des Skalarprodukts zweier Vektoren kleiner oder gleich dem Produkt der Längen der beiden Vektoren ist. Für einen Beweis der Cauchy-Schwarz-Ungleichung siehe ?thm-cauchy-schwarz-inequality.\nBetrachten wir die Vektoren x und y als Vektoren im n-dimensionalen Raum. Der Korrelationskoeffizient ist definiert als\n\nx = \\begin{pmatrix} x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_n \\end{pmatrix}, \\quad y = \\begin{pmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_n \\end{pmatrix}\n\nEs ist einfacher zu rechnen, wenn die Vektoren zentriert sind. Das bedeutet, dass wir die Mittelwerte von x und y von den Vektoren abziehen.\n\nx^{*} = x - \\overline{x} = \\begin{pmatrix} x_1 - \\overline{x} \\\\ x_2 - \\overline{x} \\\\ \\vdots \\\\ x_n - \\overline{x} \\end{pmatrix}, \\quad y^{*}  = y - \\overline{y}= \\begin{pmatrix} y_1 - \\overline{y} \\\\ y_2 - \\overline{y} \\\\ \\vdots \\\\ y_n - \\overline{y} \\end{pmatrix}\n\nDas Skalarprodukt der zentrierten Vektoren ist dann einfach die Summe im Zähler der Definition des Korrelationskoeffizienten.\n\n\\sum_{i=1}^n (x_i - \\overline{x})(y_i - \\overline{y}) = x^{*T} y^{*}\n\nNun schauen wir uns den Nenner an. Der Nenner ist das Produkt der Längen der zentrierten Vektoren.\n\n\\sqrt{\\sum_{i=1}^n (x_i - \\overline{x})^2} \\sqrt{\\sum_{i=1}^n (y_i - \\overline{y})^2} = ||x^{*}|| \\cdot ||y^{*}||\n\n\n\n\n\nnp.corrcoef(x, y)\n\narray([[1.        , 0.90067522],\n       [0.90067522, 1.        ]])\n\n\n\nnp.corrcoef(x1, y1)\n\narray([[ 1.        , -0.88100254],\n       [-0.88100254,  1.        ]])",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Die KQ-Methode</span>"
    ]
  },
  {
    "objectID": "03-KQ-Methode.html#übung",
    "href": "03-KQ-Methode.html#übung",
    "title": "8  Die KQ-Methode",
    "section": "8.5 Übung",
    "text": "8.5 Übung\nDefinieren Sie eine Funktion, die für zwei Numpy-Arrays die KQ-Koeffizienten berechnet und als eine Tupel zurückgibt.\n\nx_test = np.random.normal(size=100, loc=0, scale=1)\ny_test = 1 + 2 * x + np.random.normal(size=100, scale=1.5)\n\n\ndef ols_two_variable(x, y):\n    pass\n\n\nfrom statsmodels.formula.api import ols\n\nols(\"y ~ x\", data=pd.DataFrame({'x': x_test, 'y': y_test})).fit().params\n\nIntercept    0.762981\nx           -0.224131\ndtype: float64\n\n\n\n# Bevor wir die Funktion schreiben, versuchen wir die KQ Methode anhand \n# eines einfachen Beispiels berechnen.\n\nx1 = np.array([1, 2, 3, 4, 5])\ny1 = np.array([2, 3, 4, 5, 6])\n\n# Berechnen Sie die Koeffizienten beta_0 und beta_1\n\n# Schritt 1: Berechnen Sie die Mittelwerte von x und y\nx1_mean = x1.mean()\ny1_mean = y1.mean()\n\n# Schritt 2: Berechnen Sie den Mittelwert der quadrierten Werte von x\n\nx1_squared_mean = (x1 ** 2).mean()\n\n# Schritt 3: Berechnen Sie die Mittelwerte der Produkte von x und y\n\nxy_mean = (x1 * y1).mean()\n\n# Schritt 4: Berechnen Sie beta_1_hat\n\nbeta_1_hat = (xy_mean - x1_mean * y1_mean) / (x1_squared_mean - x1_mean ** 2)\n\n# Schritt 5: Berechnen Sie beta_0_hat\n\nbeta_0_hat = y1_mean - beta_1_hat * x1_mean\n\n\n# Wir können unsere Ergebnisse mit der statsmodels-Bibliothek überprüfen\n\nols(\"y ~ x\", data=pd.DataFrame({'x': x1, 'y': y1})).fit().params\n\nIntercept    1.0\nx            1.0\ndtype: float64",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Die KQ-Methode</span>"
    ]
  },
  {
    "objectID": "03-KQ-Methode.html#anwendung-der-kq-methode",
    "href": "03-KQ-Methode.html#anwendung-der-kq-methode",
    "title": "8  Die KQ-Methode",
    "section": "8.6 Anwendung der KQ-Methode",
    "text": "8.6 Anwendung der KQ-Methode\nNachdem wir eine Idee darüber gewonnen haben, wie die KQ-Methode die optimalen Koeffizienten in der Prognosegleichung bestimmt, lassen Sie und die KQ-Methode auf die Daten des Buchhaltungsunternehmens anwenden.\nDas Modell, das wir verwenden, ist\n\n\\widehat{\\text{Time}} = \\hat{\\beta}_0 + \\hat{\\beta}_1 \\text{Invoices}\n\n\nmodel = ols(\"Time ~ Invoices\", data=invoices).fit()\nmodel.params\n\nIntercept    0.641710\nInvoices     0.011292\ndtype: float64\n\n\nInterpretation der Koeffizienten:\n\nMaßeinheit von \\hat{\\beta}_0: ?\nMaßeinheit von \\hat{\\beta}_1: ?\nWirtschaftliche Interpretation von \\hat{\\beta}_0: ?\nWirtschaftliche Interpretation von \\hat{\\beta}_1: ?\n\nVisualisierung der Prognosen:\n\n# Zuerst berechnen wir die Prognosewerte für jeden Tag\n\n# Wir könnten die Prognosewerte \"per Hand\" ausrechnen, wie wir es oben gemacht haben.\n# Der einzige Unterschied ist es, dass wir die Koeffizienten aus dem Modell nehmen.\n\nTime_predicted_OLS_hand1 = 0.641710 + 0.011292 * invoices['Invoices']\n\n# Oder wir können die Koeffizienten aus dem Modellobjekt herauslesen\n\nTime_predicted_OLS_hand2 = model.params['Intercept'] + model.params['Invoices'] * invoices['Invoices']\n\n# Wir werden allerdings die .predict()-Methode des Modells verwenden, da es automatisch die Prognosewerte berechnet.\n\nTime_predicted_OLS = model.predict()\n\nDie Prognosewerte können wir nun graphisch darstellen\n\nfig, ax = plt.subplots()\n\nsns.scatterplot(data=invoices, x=\"Invoices\", y=\"Time\", ax=ax)\nax.plot(invoices[\"Invoices\"], Time_predicted_OLS, \"-\", color='firebrick', label=r\"$\\widehat{Time} = 0.6417 + 0.0113 \\cdot \\text{Invoices}$\")\n\nax.legend(loc=0)",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Die KQ-Methode</span>"
    ]
  },
  {
    "objectID": "03-KQ-Methode.html#die-geometrie-der-kq-methode",
    "href": "03-KQ-Methode.html#die-geometrie-der-kq-methode",
    "title": "8  Die KQ-Methode",
    "section": "8.7 Die Geometrie der KQ-Methode",
    "text": "8.7 Die Geometrie der KQ-Methode\nUm die Darstellung einfach zu halten, betrachten wir einen Datensatz mit nur zwei Beobachtungen und eine Prognosegleichung ohne Achsenabschnitt (Intercept).\n\n\\hat{y} = \\hat{\\beta}_1 x\n\n\ndt_2d = pd.DataFrame({'x': [1, 1.5], 'y': [1, 0.2]})\ndt_2d\n\n\n\n\n\n\n\n\nx\ny\n\n\n\n\n0\n1.0\n1.0\n\n\n1\n1.5\n0.2\n\n\n\n\n\n\n\nDie Daten (y-Werte) können wir als einen zweidimensionalen Vektor betrachten (eine Dimension pro jede Beobachtung). Die Prädiktorvariable x können wir auch als einen zweidimensionalen Vektor auffassen.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nX = np.array([2, 3]) / 2\nY = np.array([1, 0.2])\n\n# Create a figure\nfig, ax = plt.subplots()\nY_proj = np.dot(X, Y) / np.dot(X, X) * X\nY_min_Y_proj = Y_proj - Y\n\n# Plot the vectors\nax.quiver(0, 0, X[0], X[1], angles='xy', scale_units='xy', scale=1, color='r', label='A')\nax.quiver(0, 0, Y[0], Y[1], angles='xy', scale_units='xy', scale=1, color='b', label='B')\nax.quiver(Y[0], Y[1], Y_min_Y_proj[0], Y_min_Y_proj[1], angles='xy', scale_units='xy', scale=1, color='c', label='C')\nax.quiver(0, 0, Y_proj[0], Y_proj[1], angles='xy', scale_units='xy', scale=1, color='g', label='D')\nax.set_xlim(0, 1.5)\nax.set_ylim(0, 1.5)\n\nax.annotate('x', (X[0], X[1]), textcoords=\"offset points\", xytext=(2,-10), ha='center')\nax.annotate('y', (Y[0], Y[1]), textcoords=\"offset points\", xytext=(2,-10), ha='center')\nax.annotate(r\"$ \\hat{y} = \\hat{\\beta}_1 x$\", (Y_proj[0], Y_proj[1]), textcoords=\"offset points\", xytext=(-20,0), ha='center')\nax.annotate(r\"$\\hat{\\beta}_1 x - y$\", (Y_proj[0], Y_proj[1]), textcoords=\"offset points\", xytext=(70,-20), ha='center')\n\n\n\n\n\n\n\nText(70, -20, '$\\\\hat{\\\\beta}_1 x - y$')\n\n\n(a) Projektion des Vektors y auf den Vektor x.\n\n\n\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\n\nAbbildung 8.9\n\n\n\n\nIm zweidimensionalen können wir die Variable x als einen Vector mit Koordinaten (x_1, x_2) darstellen. Die Variable y können wir als einen Vektor mit Koordinaten (y_1, y_2) darstellen. Unsere Aufgabe ist nun, den Vektor \\hat{y} = \\hat{\\beta}_1 x so zu wählen, dass der Abstand zwischen den Vektoren y und \\hat{y} minimal ist.\nDer Abstand zwischen zwei Vektoren a und b ist definiert als die Länge des Vektors a - b. Den kleinsten Abstand erhalten wir, wenn die Zahl \\hat{\\beta}_1 so gewählt wird, dass der Vektor y - \\hat{y} senkrecht auf dem Vektor x steht. Das bedeutet, dass das Skalarprodukt von y - \\hat{y} und x gleich Null sein muss.\n\nx \\cdot (y - \\hat{y}) = 0\n\nDas Skalarprodukt von zwei Vektoren a = (a_1, a_2) und b = (b_1, b_2) ist definiert als\n\na \\cdot b = a_1 b_1 + a_2 b_2\n\noder für a = (a_1, a_2, \\ldots, a_n) und b = (b_1, b_2, \\ldots, b_n)\n\na \\cdot b = \\sum_{i=1}^n a_i b_i = a_1 b_1 + a_2 b_2 + \\ldots + a_n b_n\n\nWir können das Skalarprodukt auch als Matrixmultiplikation schreiben\n\na \\cdot b = a^T b = \\begin{pmatrix} a_1 & a_2 & \\ldots & a_n \\end{pmatrix} \\begin{pmatrix} b_1 \\\\ b_2 \\\\ \\vdots \\\\ b_n \\end{pmatrix} = a_1 b_1 + a_2 b_2 + \\ldots + a_n b_n\n\nAus der Bedingung x \\cdot (y - \\hat{y}) = 0 erhalten wir\n\n\\begin{align*}\nx^T (y - \\hat{y}) & = x^T y - x^T \\hat{y} = 0 \\\\\nx^T y & = x^T \\hat{y} \\\\\nx^T y & = x^T \\hat{\\beta}_1 x \\\\\nx^T y & = \\hat{\\beta}_1 x^T x \\\\\n\\hat{\\beta}_1 & = \\frac{x^T y}{x^T x}\n\\end{align*}\n\nIm letzten Schritt dürfen wir durch x^T x teilen, weil x^T x eine Zahl (nicht ein Vektor oder eine Matrix) und ungleich Null ist (es ist die Summe der Quadrate der Elemente von x).\nDieser Ansatz lässt sich auf mehrdimensionale Daten verallgemeinern. Die Prognosegleichung lautet dann (für p Prädiktorvariablen und n Beobachtungen)\n\n\\hat{y} = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_1 + \\hat{\\beta}_2 x_2 + \\ldots + \\hat{\\beta}_p x_p\n\nDie einzelnen Gleichungen für jede Beobachtung sind\n\n\\begin{align*}\n\\hat{y}_1 & = \\hat{\\beta}_1 x_{11} + \\hat{\\beta}_2 x_{12} + \\ldots + \\hat{\\beta}_p x_{1p} \\\\\n\\hat{y}_2 & = \\hat{\\beta}_1 x_{21} + \\hat{\\beta}_2 x_{22} + \\ldots + \\hat{\\beta}_p x_{2p} \\\\\n\\vdots & \\\\\n\\hat{y}_n & = \\hat{\\beta}_1 x_{n1} + \\hat{\\beta}_2 x_{n2} + \\ldots + \\hat{\\beta}_p x_{np}\n\\end{align*}\n\nDieses Gleichungssystem lässt sich in Matrixschreibweise darstellen\n\n\\begin{pmatrix}\n\\hat{y}_1 \\\\\n\\hat{y}_2 \\\\\n\\vdots \\\\\n\\hat{y}_n\n\\end{pmatrix}\n=\n\\begin{pmatrix}\nx_{11} & x_{12} & \\ldots & x_{1p} \\\\\nx_{21} & x_{22} & \\ldots & x_{2p} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\nx_{n1} & x_{n2} & \\ldots & x_{np}\n\\end{pmatrix}\n\\begin{pmatrix}\n\\hat{\\beta}_1 \\\\\n\\hat{\\beta}_2 \\\\\n\\vdots \\\\\n\\hat{\\beta}_p\n\\end{pmatrix}\n\noder kurz\n\n\\hat{y}_{1 \\times n} = X_{n \\times p} \\hat{\\beta}_{p \\times 1}\n\nEine ähnliche Herleitung wie oben wird verlangen, daß der Prognosevektor orthogonal auf den Spalten von X steht. Das bedeutet, daß die Matrix X^T (y - \\hat{y}) gleich Null sein muss.\n\n\\begin{align*}\nX^T (y - \\hat{y}) & = 0 \\\\\nX^T y & = X^T \\hat{y} \\\\\nX^T y & = X^T X \\hat{\\beta} \\\\\n\\end{align*}\n\nHier können wir allerdings nicht einfach durch X^T X dividieren, als wir es im zweidimensionalen Fall gemacht haben, da X^T X eine ganze Matrix ist. Wir können allerdings die Inverse der Matrix X^T X verwenden. Diese bezeichnen wir mit (X^T X)^{-1}.\nDie Inverse einer quadratischen Matrix ist eine Matrix, die, wenn sie mit der ursprünglichen Matrix multipliziert wird, die Einheitsmatrix ergibt.\n\nA A^{-1} = A^{-1} A = I\n\n\nA = np.array([[1, 2], [-2, 1]])\nA\n\narray([[ 1,  2],\n       [-2,  1]])\n\n\n\n# Mit np.linalg.inv() berechnen wir die Inverse einer Matrix\n\nA_inverse = np.linalg.inv(A)\nA_inverse\n\narray([[ 0.2, -0.4],\n       [ 0.4,  0.2]])\n\n\n\n# The @ operator is used for matrix multiplication this is different from A * A_inverse\n# A * A_inverse\n\n# Die Multiplikation von A mit der Inversen von A ergibt die Einheitsmatrix (1 auf der Diagonale, 0 sonst)\nA @ A_inverse\n\narray([[1., 0.],\n       [0., 1.]])\n\n\n\nA_inverse @ A\n\narray([[1., 0.],\n       [0., 1.]])\n\n\nFalls die Inverse von X^T X existiert, können wir die Koeffizienten \\hat{\\beta} wie folgt darstellen\n\n\\begin{align*}\n\\underbrace{(X^T X)^{-1} (X^T X)}_{I} \\hat{\\beta} = (X^T X)^{-1} X^T y \\\\\n\\hat{\\beta} = (X^T X)^{-1} X^T y\n\\end{align*}\n\nMan kann zeigen, daß die Inverse von X^T X dann existiert, wenn die Spalten von X linear unabhängig sind. Das bedeutet, daß keine Spalte durch eine Linearkombination der anderen Spalten dargestellt werden kann.\n\nX1 = np.array([[1, 2], [1, 4], [1, 2], [1, -2]])\nprint(X1)\n\nX1.T @ X1\n\n[[ 1  2]\n [ 1  4]\n [ 1  2]\n [ 1 -2]]\n\n\narray([[ 4,  6],\n       [ 6, 28]])\n\n\n\nnp.linalg.inv(X1.T @ X1)\n\narray([[ 0.36842105, -0.07894737],\n       [-0.07894737,  0.05263158]])\n\n\n\n# Schauen wir uns was passiert, wenn wir die zweite Spalte auf 2 (z.B) setzen\n\nX2 = X1.copy()\n\nX2[:, 1] = 2\nX2\n\narray([[1, 2],\n       [1, 2],\n       [1, 2],\n       [1, 2]])\n\n\n\nX2.T @ X2\n\narray([[ 4,  8],\n       [ 8, 16]])\n\n\n\n# np.linalg.inv(X2.T @ X2)\n\nDasselbe passiert, falls eine Spalte von X eine Linearkombination der anderen Spalten ist.\n\nX3 = X1.copy()\nnew_column = X3[:,0] + X3[:,1]\nprint(new_column)\n\nX3_new = np.concatenate([X3, new_column.reshape(4, 1)], axis=1)\nX3_new\n\n[ 3  5  3 -1]\n\n\narray([[ 1,  2,  3],\n       [ 1,  4,  5],\n       [ 1,  2,  3],\n       [ 1, -2, -1]])\n\n\n\n\nX3_new.T @ X3_new\n\narray([[ 4,  6, 10],\n       [ 6, 28, 34],\n       [10, 34, 44]])\n\n\n\n# np.linalg.inv(X3_new.T @ X3_new)\n\n\n# np.linalg.det(X3_new.T @ X3_new)",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Die KQ-Methode</span>"
    ]
  },
  {
    "objectID": "04a-Diskrete-Verteilungen.html",
    "href": "04a-Diskrete-Verteilungen.html",
    "title": "9  Diskrete Verteilungen",
    "section": "",
    "text": "9.1 Sampling from a univariate distribution\nIm Folgenden werden wir die Funktion choice aus der NumPy-Bibliothek verwenden, um eine Stichprobe von 10,000 Beobachtungen aus der Verteilung von X zu ziehen.\n# Das erste Argument sind die möglichen Werte\n# Das zweite Argument (p) sind die Wahrscheinlichkeiten\n# Das dritte Argument (size) ist die Anzahl der Zufallszahlen\n\nsmpl_x = np.random.choice(px[\"x\"], p = px[\"p\"], size = 10000)\n\n# Wir können uns die ersten 10 Zufallszahlen anschauen\nsmpl_x[0:10]\n\narray([3, 0, 2, 2, 3, 0, 3, 3, 3, 2])\nWir können die absoluten Häufigkeiten (Anzahl) der Werte zählen\npd.value_counts(smpl_x)\n\n/tmp/ipykernel_2413/1849734910.py:1: FutureWarning:\n\npandas.value_counts is deprecated and will be removed in a future version. Use pd.Series(obj).value_counts() instead.\n\n\n\n3    3802\n2    2756\n0    2510\n1     932\nName: count, dtype: int64\nund die relative Häufigkeit berechnen, indem wir die Anzahl durch die Gesamtzahl der Beobachtungen teilen.\npd.value_counts(smpl_x, normalize=True)\n\n/tmp/ipykernel_2413/979932776.py:1: FutureWarning:\n\npandas.value_counts is deprecated and will be removed in a future version. Use pd.Series(obj).value_counts() instead.\n\n\n\n3    0.3802\n2    0.2756\n0    0.2510\n1    0.0932\nName: proportion, dtype: float64\nsns.countplot(x = smpl_x)\n# Benutzen Sie den Code aus der vorherigen Zelle, um eine Stichprobe von $Y$ zu ziehen. Achten Sie\n# darauf, dass die Spalte mit den möglichen Werten von $Y$ \"y\" heißt.\n# Die absoluten Häufigkeiten\n# Die relativen Häufigkeiten\n# Das Balkendiagramm",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Diskrete Verteilungen</span>"
    ]
  },
  {
    "objectID": "04a-Diskrete-Verteilungen.html#sampling-from-a-univariate-distribution",
    "href": "04a-Diskrete-Verteilungen.html#sampling-from-a-univariate-distribution",
    "title": "9  Diskrete Verteilungen",
    "section": "",
    "text": "Übungsaufgabe 9.1 (Sampling from the Distribution of Y) Ziehen Sie eine Stichprobe von 10,000 Beobachtungen aus der Verteilung von Y und berechnen Sie die absoluten und die relativen Häufigkeiten der Werte und visualisieren Sie die Häufigkeiten mit einem Balkendiagramm.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Diskrete Verteilungen</span>"
    ]
  },
  {
    "objectID": "04a-Diskrete-Verteilungen.html#der-erwartungswert",
    "href": "04a-Diskrete-Verteilungen.html#der-erwartungswert",
    "title": "9  Diskrete Verteilungen",
    "section": "9.2 Der Erwartungswert",
    "text": "9.2 Der Erwartungswert\nDer Erwartungswert einer Zufallsvariablen (Verteilung) ist der gewichtete Durchschnitt aller möglichen Werte, die auftreten können. Die Gewichte sind die Wahrscheinlichkeiten, mit denen die Werte auftreten. Der Erwartungswert ist ein Maß für die Lage der Verteilung.\n\n\\begin{align}\n\\mu_x & = E(X) = \\sum_{x = 0}^{3} x p_X(x) = 0 \\times 0.250 + 1 \\times 0.095 + 2 \\times 0.272 + 3 \\times 0.383 = 1.788 \\\\\n\\end{align}\n\n\nx_expected_value = np.sum(px[\"x\"] * px[\"p\"])\nx_expected_value\n\n1.788\n\n\n\nnp.mean(smpl_x)\n\n1.785\n\n\n\nfig, ax = plt.subplots()\n\nsns.barplot(x='x', y='p', data=px, ax = ax, fill = False)\nax.axvline(x = x_expected_value, color = \"firebrick\", linestyle = \"--\")\n\n\n\n\n\n\n\n\n\nÜbungsaufgabe 9.2 (Erwartungswert) Berechnen Sie den Erwartungswert von Y.\n\nDer Erwartungswert ist die beste Vorhersage für zukünftige Werte einer Zufallsvariablen, in dem Sinne, dass er den erwarteten Wert der quadratischen Verlustfunktion minimiert:\n\nE[(X - \\hat{x})^2]\n\nLassen Sie uns ein Beispiel konstruieren. Sie müssen das Ergebnis von X vorhersagen und Sie denken, dass die beste Vorhersage \\bar{x} = 1 ist. Wenn das Spiel läuft, wird es vier mögliche Werte produzieren: 0, 1, 2 und 3. Die Fehler, den Sie machen werden, sind:\n\nL(x) = (x - 1)^2 =\n\\begin{cases}\n   (0 - 1)^2 = 1 & \\text{x = 0}\\\\\n   (1 - 1)^2 = 0 & \\text{x = 1}\\\\\n   (2 - 1)^2 = 1 & \\text{x = 2}\\\\\n   (3 - 1)^2 = 4 & \\text{x = 3}\n\\end{cases}\n\n\nÜbungsaufgabe 9.3 (Erwarteter Verlust) Berechnen Sie den erwarteten Verlust für eine Vorhersage von \\bar{x} = 1.5.\n\n\n# Berechnen Sie zuerst die Fehler\n\n# errors = ... - 1.5\n# errors\n\n\n# Danach quadrieren Sie die Fehler\n## squared_errors = ...**2\n\n\n# Zuletzt multiplizieren Sie die quadrierten Fehler mit den Wahrscheinlichkeiten und summieren Sie\n\n# np.sum(... * ...)",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Diskrete Verteilungen</span>"
    ]
  },
  {
    "objectID": "04a-Diskrete-Verteilungen.html#die-varianz",
    "href": "04a-Diskrete-Verteilungen.html#die-varianz",
    "title": "9  Diskrete Verteilungen",
    "section": "9.3 Die Varianz",
    "text": "9.3 Die Varianz\nDie Varianz einer Zufallsvariablen (Verteilung) misst, wie unterschiedlich die möglichen Werte sind, die auftreten können. Werte, die unter p_X häufiger auftreten (eine höhere Wahrscheinlichkeit haben), erhalten ein höheres Gewicht. Werte, die unter p_X seltener auftreten, erhalten ein geringeres Gewicht in der Summe.\n\nDefinition 9.1 (Varianz) Die Varianz ist als die erwartete quadratische Abweichung von dem Erwartungswert definiert\n\nVar(X) = E\\left( (X - E(X))^2\\right)\n\nFür diskrete Verteilungen ist diese Erwartung einfach der gewichtete (mit den Wahrscheinlichkeiten) Durchschnitt der quadrierten Abweichungen vom Erwartungswert.\n\nIn unserem Beispiel ist die Varianz von X:\n\nVar(X) = \\sum_{x = 0}^{3} (x - \\mu_x)^2 \\times p_X(x)\n\n\n\\begin{align}\nVar(X) & = \\sum_{x = 0}^{3} (x - \\mu_x)^2 \\times p_X(x) \\\\\n       & = (0 - 1.788)^2 \\times 0.250 + (1 - 1.788)^2 \\times 0.095 + (2 - 1.788)^2\\times 0.272 + (3 - 1.788)^2 \\times 0.383 \\\\\n       & = (-1.788)^2 \\times 0.250 + (-0.788)^2 \\times 0.095 + (0.212)^2\\times 0.272 + (1.212)^2 \\times 0.383 \\\\\n       & = 3.196 \\times 0.250 + 0.620^2 \\times 0.095 + 0.044 \\times 0.272 + 1.468 \\times 0.383 \\\\\n       & \\approx 1.433\n\\end{align}\n\\tag{9.1}\n\nnp.sum(((px[\"x\"] - x_expected_value)**2) * px[\"p\"])\n\n1.433056\n\n\n\nTheorem 9.1 (Eigenschaften des Erwartungswertes) Es sei X eine Zufallsvariable mit Erwartungswert E(X), Y eine Zufallsvariable mit Erwartungswert E(Y) und a eine feste Konstante (a \\in \\mathbb{R}). Man kann zeigen, dass die folgenden Eigenschaften gelten:\n\n\\begin{align}\nE(a) & = a \\\\\nE(aX) & = aE(X) \\\\\nE(X + Y) & = E(X) + E(Y)\n\\end{align}\n\nFerner, wenn X und Y unkorreliert sind, dann ist der Erwartungswert des Produkts der beiden Zufallsvariablen gleich dem Produkt ihrer Erwartungswerte:\n\nE(XY) = E(X)E(Y)\n\n\n\n\n\n\n\n\nProof of the Properties of the Expectation\n\n\n\n\n\n\nE(a) = a\n\nThe expected value of a discrete variable X with possible outcomes x_1, x_2, \\ldots, x_n and probabilities p_1, p_2, \\ldots, p_n is given by\n\nE(X) = \\sum_{i = 1}^{n} x_i p_i\n\nMultiplying both sides by a gives\n\naE(X) = a\\sum_{i = 1}^{n} x_i p_i = \\sum_{i = 1}^{n} ax_i p_i\n\nThe right-hand side is the expected value of a random variable that takes the values ax_1, ax_2, \\ldots, ax_n with probabilities p_1, p_2, \\ldots, p_n. Therefore, E(aX) = aE(X).\n\nE(X + Y) = E(X) + E(Y)\n\nThis proof involves the joint distribution function of X and Y which we will introduce later. The proof is based on the linearity of the expected value operator.\n\n\n\n\nTheorem 9.2 (Eigenschaften der Varianz) Es sei X eine Zufallsvariable mit Erwartungswert E(X), Y eine Zufallsvariable mit Erwartungswert E(Y) und a eine feste Konstante (a \\in \\mathbb{R}). Man kann zeigen, dass die folgenden Eigenschaften gelten:\n\nVar(X) = E(X^2) - E(X)^2\n\n\n\\begin{align}\nVar(a) & = 0 \\\\\nVar(aX) & = a^2 Var(X)\n\\end{align}\n\nFalls X und Y unkorreliert sind, dann ist die Varianz der Summe der beiden Zufallsvariablen gleich der Summe ihrer Varianzen:\n\nVar(X + Y) = Var(X) + Var(Y)\n\n\n\nÜbungsaufgabe 9.4 (Erwartungswert und Varianz) Benutzen Sie die Use the distributions of X and Y from Tabelle 9.1 and Tabelle 9.2 to compute the expected value and the variance of\n\n2X + 3Y + 1.\n\nAssume that X and Y are independent.\n\n\nLösung. \nE(2X + 3Y + 1) = \\\\\nVar(2X + 3Y + 1) =",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Diskrete Verteilungen</span>"
    ]
  },
  {
    "objectID": "04a-Diskrete-Verteilungen.html#die-gemeinsame-verteilung",
    "href": "04a-Diskrete-Verteilungen.html#die-gemeinsame-verteilung",
    "title": "9  Diskrete Verteilungen",
    "section": "9.4 Die gemeinsame Verteilung",
    "text": "9.4 Die gemeinsame Verteilung\nDie gemeinsame Wahrscheinlichkeitsmassenfunktion gibt die Wahrscheinlichkeit des gleichzeitigen Auftretens von x und y an. Zum Beispiel können Sie die Frage stellen: Was ist die Wahrscheinlichkeit von x = 2 und y = 3.\nFür zwei diskrete Zufallsvariablen ist es bequem, die PMF als eine Tabelle darzustellen. Der DataFrame pxy enthält eine Verteilung von X und Y.\n\npxy\n\n\n\n\n\n\n\n\nx\ny\np\n\n\n\n\n0\n0\n2\n0.241\n\n\n1\n0\n3\n0.009\n\n\n2\n1\n2\n0.089\n\n\n3\n1\n3\n0.006\n\n\n4\n2\n2\n0.229\n\n\n5\n2\n3\n0.043\n\n\n6\n3\n2\n0.201\n\n\n7\n3\n3\n0.182\n\n\n\n\n\n\n\nManchmal ist es allerdings einfacher, die gemeinsame Verteilung in einer Matrix zu visualisieren. Die Matrix wird als Kreuztabelle bezeichnet. Die Zeilen entsprechen den möglichen Werten von X und die Spalten den möglichen Werten von Y. Die Zellen enthalten die Wahrscheinlichkeiten.\n\npxy.pivot(index = \"x\", columns = \"y\", values = \"p\")\n\n\n\nTabelle 9.3: Joint distribution of X and Y.\n\n\n\n\n\n\n\n\n\ny\n2\n3\n\n\nx\n\n\n\n\n\n\n0\n0.241\n0.009\n\n\n1\n0.089\n0.006\n\n\n2\n0.229\n0.043\n\n\n3\n0.201\n0.182\n\n\n\n\n\n\n\n\n\n\n\np_{XY}(x=2, y=3) = 0.043\n\nWie in dem eindimensionalen Fall, müssen sich die Wahrscheinlichkeiten zu eins summieren.\n\n\\sum_{x = 0}^{3}\\sum_{y = 2}^{3} p_{XY}(x, y) = 1\n\n\nnp.sum(pxy[\"p\"])\n\n1.0",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Diskrete Verteilungen</span>"
    ]
  },
  {
    "objectID": "04a-Diskrete-Verteilungen.html#randverteilungen",
    "href": "04a-Diskrete-Verteilungen.html#randverteilungen",
    "title": "9  Diskrete Verteilungen",
    "section": "9.5 Randverteilungen",
    "text": "9.5 Randverteilungen\nAus der gemeinsamen PMF können wir die Randverteilungen von X und Y ableiten.\n\np_X(x) = \\sum_{y} p_{XY}(x, y)\n\n\npxy.groupby(\"x\")[\"p\"].sum()\n\nx\n0    0.250\n1    0.095\n2    0.272\n3    0.383\nName: p, dtype: float64\n\n\n\nÜbungsaufgabe 9.5 (Randverteilungen) Berechnen Sie die Randverteilungen von X und Y aus der gemeinsamen Verteilung p_{XY}.\n\n\n# pxy.groupby(...)[...].sum()",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Diskrete Verteilungen</span>"
    ]
  },
  {
    "objectID": "04a-Diskrete-Verteilungen.html#bedingte-verteilungen",
    "href": "04a-Diskrete-Verteilungen.html#bedingte-verteilungen",
    "title": "9  Diskrete Verteilungen",
    "section": "9.6 Bedingte Verteilungen",
    "text": "9.6 Bedingte Verteilungen\n\n\nCode\npxy[\"p_y_given_x\"] = pxy[\"p\"] / pxy.groupby(\"x\")[\"p\"].transform(\"sum\")\n\npxy.pivot(index = \"x\", columns = \"y\", values = \"p_y_given_x\")\n\n\n\n\nTabelle 9.4: Conditional distributions of Y given X\n\n\n\n\n\n\n\n\n\ny\n2\n3\n\n\nx\n\n\n\n\n\n\n0\n0.964000\n0.036000\n\n\n1\n0.936842\n0.063158\n\n\n2\n0.841912\n0.158088\n\n\n3\n0.524804\n0.475196\n\n\n\n\n\n\n\n\n\n\nDie bedingte Verteilung von Y gegeben X ist die Wahrscheinlichkeitsverteilung von Y unter der Bedingung, dass X einen bestimmten Wert annimmt. Die bedingte Verteilung wird als p_{Y|X}(y | x) geschrieben.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Diskrete Verteilungen</span>"
    ]
  },
  {
    "objectID": "04a-Diskrete-Verteilungen.html#unabhängigkeit",
    "href": "04a-Diskrete-Verteilungen.html#unabhängigkeit",
    "title": "9  Diskrete Verteilungen",
    "section": "9.7 Unabhängigkeit",
    "text": "9.7 Unabhängigkeit\nZwei Zufallsvariablen sind unabhängig, wenn das Ergebnis einer der Variablen die Wahrscheinlichkeitsverteilung der anderen nicht beeinflusst. Stellen Sie sich vor, Sie haben zwei Lottoscheine: einen von einer Lotterie in Deutschland und einen von einer Lotterie in Bulgarien. Es wäre sicher anzunehmen, dass die realisierten Gewinne der deutschen Lotterie die Gewinnchancen des bulgarischen Tickets nicht beeinflussen.\nBetrachten wir nun den Fall von abhängigen Zufallsvariablen. Sei X der Pegel eines Flusses (an einer Messstelle) zur Zeit t und Y der Pegel des gleichen Flusses fünf Minuten später. Es wäre sicher anzunehmen, dass wenn der Pegel des Flusses bei t hoch war, dies die Verteilung des Niveaus des Flusses bei t plus fünf Minuten beeinflussen würde.\n\nDefinition 9.2 (Unabhängigkeit) Zwei Zufallsvariablen X und Y sind unabhängig, wenn die gemeinsame PMF gleich dem Produkt der Randverteilungen ist.\n\np_{XY}(x, y) = p_X(x)p_Y(y)\n\n\n\n9.7.1 Bedingte Verteilungen unter Unabhängigkeit\nWir können die gemeinsame Verteilung p_{XY}(x, y) unter der Annahme der Unabhängigkeit von X und Y konstruieren, indem Wir für jede mögliche Kombination von X und Y das Produkt der Randverteilungen berechnen.\n\np_{XY}(x, y) = p_X(x)p_Y(y)\n\n\n\nCode\npxy['p_x'] = pxy.groupby('x')['p'].transform('sum')\npxy['p_y'] = pxy.groupby('y')['p'].transform('sum')\n\npxy['p_xy_ind'] = pxy['p_x'] * pxy['p_y']\n\npxy.pivot(index = \"x\", columns = \"y\", values = \"p_xy_ind\")\n\n\n\n\n\n\n\n\ny\n2\n3\n\n\nx\n\n\n\n\n\n\n0\n0.19000\n0.06000\n\n\n1\n0.07220\n0.02280\n\n\n2\n0.20672\n0.06528\n\n\n3\n0.29108\n0.09192\n\n\n\n\n\n\n\nNun schauen wir uns die bedingte Verteilung von Y gegeben X an. Die bedingte Verteilung von Y gegeben X unter der Annahme der Unabhängigkeit ist gleich der Randverteilung von Y.\n\n\nCode\npxy[\"p_y_given_x_ind\"] = pxy[\"p_xy_ind\"] / pxy.groupby(\"x\")[\"p_xy_ind\"].transform(\"sum\")\npxy.pivot(index = \"x\", columns = \"y\", values = \"p_y_given_x_ind\")\n\n\n\n\nTabelle 9.5: Joint distribution of X and Y under independence.\n\n\n\n\n\n\n\n\n\ny\n2\n3\n\n\nx\n\n\n\n\n\n\n0\n0.76\n0.24\n\n\n1\n0.76\n0.24\n\n\n2\n0.76\n0.24\n\n\n3\n0.76\n0.24",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Diskrete Verteilungen</span>"
    ]
  },
  {
    "objectID": "04a-Diskrete-Verteilungen.html#der-bedingte-erwartungswert",
    "href": "04a-Diskrete-Verteilungen.html#der-bedingte-erwartungswert",
    "title": "9  Diskrete Verteilungen",
    "section": "9.8 Der bedingte Erwartungswert",
    "text": "9.8 Der bedingte Erwartungswert\nWir haben gesehen, wie wir die bedingten Verteilungen von Y gegeben X im vorherigen Abschnitt hergeleitet haben. Nun können wir die Frage stellen: Was ist der Erwartungswert von Y, wenn X bereits den Wert 0 angenommen hat (zum Beispiel). Wir können die bedingte Verteilung von Y gegeben X = 0 nehmen und den Erwartungswert dieser Verteilung berechnen.\nFür die unabhängige gemeinsame Verteilung in Tabelle 9.5 ist der bedingte Erwartungswert von Y gegeben X = 0:\n\nE(Y | X=0) = \\sum_{y = 2}^{3} y p_{Y|X=0}(y) = 2 \\times 0.76 + 3 \\times 0.24 = 2.24\n\nFür die abhängige gemeinsame Verteilung in Tabelle 9.3 ist der bedingte Erwartungswert von Y gegeben X = 0:\n\nE(Y | X=0) = \\sum_{y = 2}^{3} y p_{Y|X=0}(y) = 2 \\times 0.964 + 3 \\times 0.036 = 2.036\n\n2 * 0.964 + 3 * 0.036\nWir können den bedingten Erwartungswert von Y für jeden möglichen Wert von X berechnen.\n\nE(Y | X = x) = \\begin{cases}\n  2.036 & \\text{for } x = 0 \\\\\n  2.060 & \\text{for } x = 1 \\\\\n  2.158 & \\text{for } x = 2 \\\\\n  2.475 & \\text{for } x = 3\n\\end{cases}\n\n\n\nCode\npxy.groupby(\"x\").apply(lambda x: np.sum(x[\"p_y_given_x_ind\"] * x[\"y\"]))\n\n\n/tmp/ipykernel_2413/3384244227.py:1: DeprecationWarning:\n\nDataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n\n\n\n\n\nTabelle 9.6: Bedingte Erwartungswerte von Y für alle mögliche Werte von X unter Unabhängigkeit.\n\n\n\nx\n0    2.24\n1    2.24\n2    2.24\n3    2.24\ndtype: float64\n\n\n\n\n\n\n\nCode\npxy.groupby(\"x\").apply(lambda x: np.sum(x[\"p_y_given_x\"] * x[\"y\"]))\n\n\n/tmp/ipykernel_2413/388503762.py:1: DeprecationWarning:\n\nDataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n\n\n\n\n\nTabelle 9.7: Bedingte Erwartungswerte von Y für alle mögliche Werte von X unter Abhängigkeit.\n\n\n\nx\n0    2.036000\n1    2.063158\n2    2.158088\n3    2.475196\ndtype: float64\n\n\n\n\n\nIm Fall der abhängigen Variablen ist der bedingte Erwartungswert von Y gegeben X nicht konstant, sondern variiert mit X.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Diskrete Verteilungen</span>"
    ]
  },
  {
    "objectID": "04b-Stetige-Verteilungen.html",
    "href": "04b-Stetige-Verteilungen.html",
    "title": "10  Die Gleichverteilung auf [-1, 1]",
    "section": "",
    "text": "10.1 Die Normalverteilung\nDie Familie der Normalverteilungen wird durch zwei Parameter definiert: den Erwartungswert \\mu und die Standardabweichung \\sigma. Die Dichte der Normalverteilung ist gegeben durch die Formel:\nf(x) = \\frac{1}{\\sqrt{2\\pi}\\sigma} \\exp\\left(-\\frac{(x - \\mu)^2}{2\\sigma^2}\\right)\nWeil wir diese Verteilung sehr oft benutzen werden, führen wir eine spezielle Notation für die Normalverteilung ein:\nX \\sim N(\\mu, \\sigma^2)\nIn dieser Notation bedeutet X ist normalverteilt mit Erwartungswert \\mu und Varianz \\sigma^2. Sie brauchen die Formel für die Dichte der Normalverteilung nicht auswendig zu lernen, allerdings müssen Sie wissen, wie die Dichte in Abhängigkeit von den Parametern \\mu und \\sigma aussieht.\n\\begin{align*}\nE(X) & = \\mu \\\\\nVar(X) & = \\sigma^2\n\\end{align*}\n# Define the means and standard deviations\nmeans = [0, 2]\nsds = [0.2, 0.5, 1]\n\n# Create a grid of x values\nx = np.linspace(-3, 5, 200)\n\n# Create a DataFrame with all combinations of means, sds, and x values\ndf = pd.DataFrame([(mean, sd, x_val, stats.norm.pdf(x_val, mean, sd)) \n                   for mean in means for sd in sds for x_val in x], \n                  columns=['mean', 'sd', 'x', 'y'])\n\n# Create labels for mean and sd\ndf['mean'] = 'mu = ' + df['mean'].astype(str)\ndf['sd'] = 'sigma = ' + df['sd'].astype(str)\n\n# Plot\nplt.figure(figsize=(8, 6))\nsns.lineplot(data=df, x='x', y='y', hue='mean', style='sd')\nplt.xlabel('x')\nplt.ylabel('Dichte')\n\n/usr/share/miniconda/envs/econ2024/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning:\n\nuse_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n\n/usr/share/miniconda/envs/econ2024/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning:\n\nuse_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n\n\n\nText(0, 0.5, 'Dichte')\nEine Art und Weise, wie eine Normalverteilung entstehen kann, ist die Summe von unabhängigen Zufallsvariablen. Das ist der Inhalt des Zentralen Grenzwertsatzes, der besagt, dass die Summe von unabhängigen Zufallsvariablen, die nicht notwendigerweise normalverteilt sind, für eine große Anzahl von Summanden normalverteilt ist.\nUm den Zentralen Grenzwertsatz zu illustrieren, betrachten wir das folgende Spiel.\nplayers_n = 300\ngames_n = 16\n\n# Create a DataFrame similar to expand_grid in R\nunif_games = pd.DataFrame(\n    np.array(\n        np.meshgrid(\n            np.arange(1, games_n + 1),\n            np.arange(1, players_n + 1)\n        )).T.reshape(-1, 2),\n    columns=['game', 'player']\n)\n\n# Add result column with random uniform values between -1 and 1\nunif_games['result'] = np.random.uniform(-1, 1, size=len(unif_games))\n\n# Add initial values for each player\ninitial_values = pd.DataFrame(\n    {'player': np.arange(1, players_n + 1), 'game': 0, 'result': 0})\nunif_games = pd.concat([unif_games, initial_values])\n\n# Sort values and calculate running total for each player\nunif_games = unif_games.sort_values(['player', 'game'])\nunif_games['running_total'] = unif_games.groupby('player')['result'].cumsum()\n\n# Plotting\nplt.figure(figsize=(10, 6))\nfor player in unif_games['player'].unique():\n    player_data = unif_games[unif_games['player'] == player]\n    plt.plot(player_data['game'], player_data['running_total'],\n             color='skyblue', alpha=0.2)\n\n# First player\nplayer_data = unif_games[unif_games['player'] == 1]\nplt.plot(player_data['game'], player_data['running_total'],\n         color='firebrick', label='Player 1')\n\nplt.axhline(0, color='black')\n\nfor mark in [4, 8, 16]:\n    plt.axvline(x=mark, linestyle='--', color='black')\n\nplt.xlabel('Spiel')\nplt.ylabel('Gesamtgewinn')\nplt.xticks([0, 4, 8, 12, 16])\n\n([&lt;matplotlib.axis.XTick at 0x7f04b862add0&gt;,\n  &lt;matplotlib.axis.XTick at 0x7f04b8628ed0&gt;,\n  &lt;matplotlib.axis.XTick at 0x7f04b8fde2d0&gt;,\n  &lt;matplotlib.axis.XTick at 0x7f04b82c59d0&gt;,\n  &lt;matplotlib.axis.XTick at 0x7f04b82c7710&gt;],\n [Text(0, 0, '0'),\n  Text(4, 0, '4'),\n  Text(8, 0, '8'),\n  Text(12, 0, '12'),\n  Text(16, 0, '16')])\ngame_4 = unif_games[unif_games['game'] == 4]\n\nplt.figure(figsize=(8, 6))\nsns.kdeplot(data=game_4, x='running_total', fill=True)\nplt.title('Running total distribution at the 4-th game')\nplt.xlabel('Running total')\n\n/usr/share/miniconda/envs/econ2024/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning:\n\nuse_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n\n\n\nText(0.5, 0, 'Running total')\n# Erstellen Sie die Dichteschätzung für das 8. Spiel und das 16. Spiel.\n\ngame_8 = unif_games[unif_games['game'] == 8]\n\nplt.figure(figsize=(8, 6))\nsns.kdeplot(data=game_8, x='running_total', fill=True)\nplt.title('Running total distribution at the 8-th game')\nplt.xlabel('Running total')\n\n/usr/share/miniconda/envs/econ2024/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning:\n\nuse_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n\n\n\nText(0.5, 0, 'Running total')\ngame_16 = unif_games[unif_games['game'] == 16]\n\nplt.figure(figsize=(8, 6))\nsns.kdeplot(data=game_16, x='running_total', fill=True)\nplt.title('Running total distribution at the 16-th game')\nplt.xlabel('Running total')\n\n/usr/share/miniconda/envs/econ2024/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning:\n\nuse_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n\n\n\nText(0.5, 0, 'Running total')",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Die Gleichverteilung auf \\[-1, 1\\]</span>"
    ]
  },
  {
    "objectID": "05-Einweg-Varianzanalyse.html",
    "href": "05-Einweg-Varianzanalyse.html",
    "title": "11  ANOVA",
    "section": "",
    "text": "11.1 Das Modell\n\\begin{align*}\n& i = 1,\\ldots, n = 434 \\text{ observations}\\\\\n& y_i: \\text{IQ score} \\\\\n& \\hat{y}_i: \\text{Predicted IQ score} \\\\\n& x_i \\in \\{0, 1\\}: \\text{status of the mother}\n\\end{align*}\ny_i = \\beta_0 + \\beta_1 x_i + e_i, e_i \\sim N(0, \\sigma^2)\n\\begin{align*}\n& y_i \\sim N(\\mu_i, \\sigma^2), \\quad i = 1,\\ldots,n \\\\\n& \\mu_i = \\beta_0 + \\beta_1 x_i, \\quad x_i \\in \\{0, 1\\}\n\\end{align*}\n\\tag{11.1}\n\\mu_1 = \\beta_0 + \\beta_1 \\cdot 1\n\\tag{11.2}\nFür x = 0\n\\mu_0 = \\beta_0 + \\beta_1 \\cdot 0\n\\tag{11.3}\nDie Differenz der zwei Gleichungen 11.2 und 11.3 ergibt:\n\\begin{align*}\n\\beta_0 & = \\mu_0 \\\\\n\\beta_1 & = \\mu_1 - \\mu_0\n\\end{align*}\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\n# Define the range of x\nx = np.linspace(0, 180, 1000)\n\n# Calculate the densities of the normal distributions\ny1 = norm.pdf(x, loc=77, scale=20)\ny2 = norm.pdf(x, loc=100, scale=20)\n\n# Create the plot\nplt.figure(figsize=(8, 6))\nplt.plot(x, y1, color='steelblue', label='Mutter ohne HS')\nplt.plot(x, y2, color='firebrick', label='Mother mit HS')\nplt.axvline(x=77, linestyle='--', alpha=0.5, color='firebrick')\nplt.axvline(x=100, linestyle='--', alpha=0.5, color='steelblue')\nplt.text(90, 0.005, r'$\\beta_1$', verticalalignment='bottom', horizontalalignment='center')\nplt.xlim([0, 180])\nplt.xlabel('IQ score')\nplt.ylabel('Dichte')\nplt.legend(loc='upper right')\nBerechnen Sie die Koeffizienten der folgenden Prognosegleichung für den IQ-Wert eines Kindes:\n\\hat{y} = \\hat{\\beta}_0 + \\hat{\\beta}_1 \\cdot x\nwobei y der IQ-Wert des Kindes ist, x die Variable mom_hs und \\hat{y} die Prognose für den IQ-Wert ist. Benutzen Sie https://febse.github.io/econ2024-de/03-KQ-Methode.html#%C3%BCbung",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>ANOVA</span>"
    ]
  },
  {
    "objectID": "05-Einweg-Varianzanalyse.html#simulation",
    "href": "05-Einweg-Varianzanalyse.html#simulation",
    "title": "11  ANOVA",
    "section": "11.2 Simulation",
    "text": "11.2 Simulation\nUm die statistischen Eigenschaften der KQ-Schätzer für die Koeffizienten zu untersuchen, führen wir eine Simulation durch. Wir werden die folgenden Schritte durchführen:\n\nWir generieren n = 434 Beobachtungen für die IQ-Werte der Kinder und die Variable mom_hs basierend auf dem Modell\n\n\n\\begin{align*}\n& y_i = 80 + 15 x_i + e_i, e_i \\sim N(0, 20^2) \\\\\n& x_i \\in \\{0, 1\\}\n\\end{align*}\n\n\nnp.random.seed(123)\n\n# Die Anzahl der Stichproben\nB = 1000\n\n# Die Anzahl der Beobachtungen pro Stichprobe\nN = 434\n\n# \ne = np.random.normal(loc=0, scale=20, size=N * B)\n\n# Für jedes Kind wir der Bildungsstatus der Mutter zufällig generiert\n# so dass circa 80% der Mütter einen High-School-Abschluss haben\n\nx = np.random.binomial(n=1, p=0.8, size=N * B)\n\ny = 80 + 15*x + e\nsample_id = np.repeat(np.arange(1, B+1), N)\n\nall_samples = pd.DataFrame({'sim_id': sample_id, 'kid_score': y, 'mom_hs': x})\n\n# Fit the models\n\n\ndef fit_ols(dat):\n    fit = ols('kid_score ~ mom_hs', dat).fit()\n\n    return pd.Series({\n        'intercept': fit.params['Intercept'],\n        'intercept_se': fit.bse['Intercept'],\n        'slope': fit.params['mom_hs'],\n        'slope_se': fit.bse['mom_hs']\n    })\n\nsim = all_samples.groupby('sim_id').apply(fit_ols)\n\n/tmp/ipykernel_2483/1235863640.py:35: DeprecationWarning:\n\nDataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n\n\n\n\nÜbungsaufgabe 11.1 Benutzen Sie die Daten der ersten Stichprobe aus der Simulation, um die Koeffizienten \\beta_0 und \\beta_1 zu schätzen. Hinweis: Benutzen Sie die Funktion ols aus dem Paket statsmodels in Python.\n\n\nsample_1 = all_samples[all_samples['sim_id'] == 1]\nfit_sample1 = ols('kid_score ~ mom_hs', sample_1).fit()\nfit_sample1.params\n\nIntercept    80.685154\nmom_hs       12.612303\ndtype: float64",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>ANOVA</span>"
    ]
  },
  {
    "objectID": "05-Einweg-Varianzanalyse.html#verteilung-der-koeffizienten",
    "href": "05-Einweg-Varianzanalyse.html#verteilung-der-koeffizienten",
    "title": "11  ANOVA",
    "section": "11.3 Verteilung der Koeffizienten",
    "text": "11.3 Verteilung der Koeffizienten\n\nfig, ax = plt.subplots(figsize=(8, 6))\nsns.stripplot(x='slope', data=sim, jitter=0.2, alpha=0.3, ax=ax)\nsns.boxplot(x='slope', data=sim, ax=ax, color='white', width=0.3)\nplt.axvline(x=15, color='red', linestyle='--')\nsns.kdeplot(x='slope', data=sim, color='black', bw_adjust=-1)\n\nax.set_ylabel(\"Dichte\")\nax.set_xlabel(r\"Steigung ($\\hat{\\beta}_1$)\")\n\n/usr/share/miniconda/envs/econ2024/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning:\n\nuse_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n\n/usr/share/miniconda/envs/econ2024/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning:\n\nuse_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n\n/usr/share/miniconda/envs/econ2024/lib/python3.11/site-packages/seaborn/_oldcore.py:1075: FutureWarning:\n\nWhen grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n\n/usr/share/miniconda/envs/econ2024/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning:\n\nuse_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n\n/usr/share/miniconda/envs/econ2024/lib/python3.11/site-packages/scipy/stats/_kde.py:591: RuntimeWarning:\n\ninvalid value encountered in log\n\n\n\n\n\n\n\n\nText(0.5, 0, 'Steigung ($\\\\hat{\\\\beta}_1$)')\n\n\n(a) Die geschätzten Steigungen der Regressionsgeraden in 1000 simulierten Stichproben. Die rote Linie zeigt den wahren Wert der Steigung. Die Streuung der Punkte (Schätzungen) in der y-Richtung enthalten keine Information und dienen nur der besseren Visualisierung.\n\n\n\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\n\nAbbildung 11.2\n\n\n\n\n\nsim[\"slope\"].mean()\n\n14.979094621402087\n\n\n\nsim[\"slope\"].std()\n\n2.3983789144793035\n\n\n\nfit_sample1.summary()\n\n\nOLS Regression Results\n\n\nDep. Variable:\nkid_score\nR-squared:\n0.057\n\n\nModel:\nOLS\nAdj. R-squared:\n0.054\n\n\nMethod:\nLeast Squares\nF-statistic:\n25.90\n\n\nDate:\nSat, 08 Jun 2024\nProb (F-statistic):\n5.38e-07\n\n\nTime:\n12:41:52\nLog-Likelihood:\n-1913.3\n\n\nNo. Observations:\n434\nAIC:\n3831.\n\n\nDf Residuals:\n432\nBIC:\n3839.\n\n\nDf Model:\n1\n\n\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\nIntercept\n80.6852\n2.241\n35.996\n0.000\n76.280\n85.091\n\n\nmom_hs\n12.6123\n2.478\n5.089\n0.000\n7.741\n17.483\n\n\n\n\n\n\nOmnibus:\n0.192\nDurbin-Watson:\n1.978\n\n\nProb(Omnibus):\n0.908\nJarque-Bera (JB):\n0.216\n\n\nSkew:\n0.051\nProb(JB):\n0.898\n\n\nKurtosis:\n2.959\nCond. No.\n4.49\n\n\n\nNotes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>ANOVA</span>"
    ]
  },
  {
    "objectID": "05-Einweg-Varianzanalyse.html#hypothesentests",
    "href": "05-Einweg-Varianzanalyse.html#hypothesentests",
    "title": "11  ANOVA",
    "section": "11.4 Hypothesentests",
    "text": "11.4 Hypothesentests\n\nTesten Sie die Nullhypothese, dass der Koeffizient \\beta_1 gleich 0 ist gegen die Alternative, dass \\beta_1 größer als 0 ist.\n\n\n\\begin{align*}\nH_0: & \\beta_1 \\leq 0 \\\\\nH_1: & \\beta_1 &gt; 0\n\\end{align*}\n\n\nTesten Sie die Nullhypothese, dass der Koeffizient \\beta_0 gleich 15 ist gegen die Alternative, dass \\beta_0 grösser als 15 ist.\n\n\n\\begin{align*}\nH_0: & \\beta_1 \\leq 15 \\\\\nH_1: & \\beta_1 &gt; 15\n\\end{align*}\n\nBerechnen Sie die Teststatistik in jeder Stichprobe\n\nt = \\frac{\\hat{\\beta}_1 - \\beta_1^{H_0}}{\\text{SE}(\\hat{\\beta}_1)}\n\nfür beide Hypothesen.\n\n# Berechnen Sie die t-statistik für die Nullhypothese H_0: \\beta_1 &gt;= 15\n\n\n\n# Visualisieren Sie die Verteilung der t-Statistiken mittels eines strip plots und einer Kerndichteschätzung.\n\n# sns.stripplot(x=..., jitter=0.2, alpha=0.3)\n# sns.kdeplot(x=..., color='black', bw_adjust=-1)\n\n\n# Berechnen Sie den Mittelwert der t-Statistiken\n\n\n# In wie vielen Stichproben ist die t-Statistik kleiner als -2?\n\nMan kann zeigen, dass under der Nullhypothese t eine t-Verteilung mit n - p Freiheitsgraden hat. Dabei ist n die Anzahl der Beobachtungen und p die Anzahl der Koeffizienten im Regressionsmodell.\n\nt \\sim t(n - p)\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import t\n\n# Define the degrees of freedom and the quantiles\ndf = 10\nquantiles = [0.05]\n\n# Compute the t-distribution density\nx = np.linspace(t.ppf(0.001, df), t.ppf(0.999, df), 1000)\ny = t.pdf(x, df)\ny1 = t.pdf(x, df=2)\n\n# Compute the quantiles\nq_values = t.ppf(quantiles, df)\n\n# Plot the density\nplt.plot(x, y, label=f't-Verteilung (df={df})', color='black')\nplt.plot(x, y1, label=f't-Verteilung (df=2)', color='firebrick')\n\n# Add vertical lines and annotations for the quantiles\nfor q in q_values:\n    plt.axvline(q, color='black', linestyle='--')\n    plt.text(q, 0.02, f'q={q:.2f}', verticalalignment='bottom', horizontalalignment='left')\n\nplt.legend(loc='upper right')\nplt.show()\n\n\n\n\n\n\n\n\nIm scipy Paket gibt es die Funktion t.ppf (percent point function), mit der wir Quantile von t-Verteilungen berechnen können. Die Funktion hat zwei Argumente: die Wahrscheinlichkeit und die Anzahl der Freiheitsgrade. Zum Beispiel, um das 95% Quantil der t-Verteilung mit 10 Freiheitsgraden zu berechnen, benutzen wir den folgenden Code:\nfrom scipy.stats import t\nt.ppf(0.95, 10)\n\nt.ppf(0.025, df=10)\n\n-2.2281388519649385\n\n\n\nt.cdf(-2.2281388519649385, df=10)\n\n0.02500000000090431\n\n\n\nt.ppf(0.975, df=10)\n\n2.2281388519649385\n\n\n\nt.cdf(2.2281388519649385, df=10)\n\n0.9749999999990957\n\n\n\n# Berechnen Sie den 0.05-Quantil der t-Verteilung mit 434 - 2 Freiheitsgraden.\n\n\n# Nehmen Sie an, dass wir die Nullhypothese für Werte der t-Statistik kleiner als das 0.05 Quantil der t-Verteilung (mit den entsprechen Freiheitsgraden) ablehnen.\n# In wie vielen Stichproben werden wir eine falsche Entscheidung treffen?\n\n\nDer p-Wert (p-value) ist die Wahrscheinlichkeit, dass die Teststatistik t extremer (d.h. in der Alternative) ist als der beobachtete Wert. In unserem Beispiel ist es die Wahrscheinlichkeit, dass t kleiner als die beobachtete Teststatistik ist, wenn die Nullhypothese wahr ist.\n\np = P(t \\leq t_{\\text{obs}} | H_0)\n\nBeachten Sie, dass die t-Statistik von den Daten abhängt und daher in jeder Stichprobe unterschiedlich ist. Daher ist auch der p-Wert in jeder Stichprobe unterschiedlich.\n\n# Berechnen Sie die p-Werte für die t-Statistiken aus der Simulation für die Nullhypothese H_0: \\beta_1 &gt;= 15\n\n\n\n# In wie vielen Stichproben ist der p-Wert kleiner als 0.05?\n\n\n\nÜbungsaufgabe 11.2 (Übungsaufgabe) Für die Nullhypothese\n\n\\begin{align*}\nH_0: \\beta_1 \\leq 0 \\\\\nH_1: \\beta_1 &gt; 0\n\\end{align*}\n\n\nBerechnen Sie die Teststatistik t in jeder Stichprobe\nBerechnen Sie den p-Wert in jeder Stichprobe\nZählen Sie die Anzahl der Stichproben, in denen der p-Wert kleiner als 0.05 ist. Dies ist die Anzahl der Stichproben, in denen wir die Nullhypothese ablehnen würden.\nFalls Sie die Nullhypothese für p-Werte kleiner als 0.05 verwerfen, berechnen Sie den Anteil der Stichproben, in denen Sie eine falsche Entscheidung treffen\nBerechnen Sie den kritischen Wert für diese Hypothese bei einem Signifikanzniveau von 0.01.\n\n\n\nÜbungsaufgabe 11.3 (Übungsaufgabe) Für die Nullhypothese\n\n\\begin{align*}\nH_0: & \\beta_0 = 0 \\\\\nH_1: & \\beta_0 \\neq 0\n\\end{align*}\n\n\nBerechnen Sie die Teststatistik t in jeder Stichprobe\nBerechnen Sie den p-Wert in jeder Stichprobe\nZählen Sie die Anzahl der Stichproben, in denen der p-Wert kleiner als 0.05 ist. Dies ist die Anzahl der Stichproben, in denen wir die Nullhypothese ablehnen würden.\nFalls Sie die Nullhypothese für p-Werte kleiner als 0.05 verwerfen, berechnen Sie den Anteil der Stichproben, in denen Sie eine falsche Entscheidung treffen\nBerechnen Sie die kritische Werte für diese Hypothese bei einem Signifikanzniveau von 0.1. Achten Sie darauf, dass Sie hier sowohl für zu große als auch zu kleine Werte der Teststatistik ablehnen müssen.\n\n\n\na = np.random.normal(loc=20, scale=10, size=1000)\nprint(np.mean(a))\n\nnp.sum(a - np.mean(a))\n\n20.55674325875171\n\n\n3.0340174816956278e-12",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>ANOVA</span>"
    ]
  },
  {
    "objectID": "05-Einweg-Varianzanalyse.html#konfidenzintervalle",
    "href": "05-Einweg-Varianzanalyse.html#konfidenzintervalle",
    "title": "11  ANOVA",
    "section": "11.5 Konfidenzintervalle",
    "text": "11.5 Konfidenzintervalle\nIn dem Regressionsmodell hängen die Schätzungen der Koeffizienten von den Daten ab und sind daher zufällig (siehe Abbildung 11.2). Deswegen ist es sinnvoll, zusammen mit dem geschätzten Koeffizienten ein Intervall von plausiblen Werten für den unbekannten wahren Koeffizienten anzugeben. Für die Koeffizienten in dem Regressionsmodell haben wir bisher die Verteilung der t-Statistik benutzt, um Hypothesentests durchzuführen. Diese Verteilung können wir auch benutzen, um Konfidenzintervalle zu berechnen.\n$$ \\begin{align*}\n    \n\\end{align*} $$",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>ANOVA</span>"
    ]
  },
  {
    "objectID": "05-Einweg-Varianzanalyse.html#anhang",
    "href": "05-Einweg-Varianzanalyse.html#anhang",
    "title": "11  ANOVA",
    "section": "11.6 Anhang",
    "text": "11.6 Anhang\nWie können wir den Erwartungswert und die Varianz der Schätzer für \\beta_0 und \\beta_1 berechnen?\nWir können die Formel für \\hat{\\beta}_1 als eine Linearkombination von y_i schreiben:\n\n\\begin{align*}\n\\hat{\\beta}_1 & = \\frac{\\sum_{i=1}^{n}(x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^{n}(x_i - \\bar{x})^2} \\\\\n& = \\frac{\\sum_{i=1}^{n}(x_i - \\bar{x})y_i}{\\sum_{i=1}^{n}(x_i - \\bar{x})^2} \\\\\n& = \\sum_{i = 1}^{n} w_i y_i\n\\end{align*}\n\nmit\n\nw_i = \\frac{x_i - \\bar{x}}{\\sum_{i=1}^{n}(x_i - \\bar{x})^2}\n\nDas dürfen wir tun, denn es gilt:\n\n\\begin{align*}\n\\sum_{i=1}^{n}(x_i - \\bar{x})(y_i - \\bar{y}) & = \\sum_{i=1}^{n}\\left((x_i - \\bar{x})y_i + (x_i - \\bar{x})\\bar{y} \\right) \\\\\n& = \\sum_{i=1}^{n}(x_i - \\bar{x})y_i + \\sum_{i=1}^{n}(x_i - \\bar{x})\\bar{y} \\\\\n& = \\sum_{i=1}^{n}(x_i - \\bar{x})y_i + \\bar{y}\\sum_{i=1}^{n}(x_i - \\bar{x}) \\\\\n& = \\sum_{i=1}^{n}(x_i - \\bar{x})y_i\n\\end{align*}\n\nDer bedingte Erwartungswert von \\hat{\\beta}_1 gegeben x ist:\n\n\\begin{align*}\nE(\\hat{\\beta}_1 | x) & = E\\left(\\sum_{i = 1}^{n} w_i y_i | x \\right) \\\\\n& = \\sum_{i = 1}^{n} w_i E(y_i | x) \\\\\n& = \\sum_{i = 1}^{n} w_i \\mu_i \\\\\n& = \\sum_{i = 1}^{n} w_i (\\beta_0 + \\beta_1 x_i) \\\\\n& = \\beta_0 \\sum_{i = 1}^{n} w_i + \\beta_1 \\sum_{i = 1}^{n} w_i x_i \\\\\n\\end{align*}\n\nDie Summe der Koeffizienten w_i ist gleich 0, weil:\n\n\\begin{align*}\n\\sum_{i = 1}^{n} w_i & = \\frac{\\sum_{i=1}^{n}(x_i - \\bar{x})}{\\sum_{i=1}^{n}(x_i - \\bar{x})^2} \\\\\n& = \\frac{\\sum_{i=1}^{n}x_i - n\\bar{x}}{\\sum_{i=1}^{n}(x_i - \\bar{x})^2} \\\\\n& = \\frac{n\\bar{x} - n\\bar{x}}{\\sum_{i=1}^{n}(x_i - \\bar{x})^2} \\\\\n& = 0\n\\end{align*}\n\nDer Factor vor \\beta_1 ist:\n\n\\begin{align*}\n\\sum_{i = 1}^{n} w_i x_i & = \\frac{\\sum_{i=1}^{n}(x_i - \\bar{x})x_i}{\\sum_{i=1}^{n}(x_i - \\bar{x})^2} \\\\\n\\end{align*}\n\nund ist gleich 1, weil:\n\n\\begin{align*}\n\\sum_{i = 1}^{n} (x_i - \\bar{x})^2 = \\sum_{i = 1}^{n} (x_i - \\bar{x})x_i\n\\end{align*}\n\nAm Ende erhalten wir:\n\n\\begin{align*}\nE(\\hat{\\beta}_1 | x) & = \\beta_1\n\\end{align*}\n\nDie bedingte Varianz von \\hat{\\beta}_1 gegeben x ist:\n\n\\begin{align*}\n\\text{Var}(\\hat{\\beta}_1 | x) & = \\text{Var}\\left(\\sum_{i = 1}^{n} w_i y_i | x \\right) \\\\\n& = \\sum_{i = 1}^{n} w_i^2 \\text{Var}(y_i | x) \\\\\n& = \\sum_{i = 1}^{n} w_i^2 \\sigma^2 \\\\\n& = \\sigma^2 \\sum_{i = 1}^{n} w_i^2\n\\end{align*}\n\nUm auf diese Formel zu kommen, haben wir vorausgesetzt, dass gegeben x, die Beobachtungen unkorreliert sind. Wenn wir die Summe der quadrierten Koeffizienten w_i vereinfachen, erhalten wir\n\n\\begin{align*}\n\\sum_{i = 1}^{n} w_i^2 & = \\sum_{i = 1}^{n} \\frac{(x_i - \\bar{x})^2}{(\\sum_{i=1}^{n}(x_i - \\bar{x})^2)^2} \\\\\n& = \\frac{\\sum_{i = 1}^{n}(x_i - \\bar{x})^2}{(\\sum_{i=1}^{n}(x_i - \\bar{x})^2)^2} \\\\\n& = \\frac{1}{\\sum_{i=1}^{n}(x_i - \\bar{x})^2}\n\\end{align*}\n\nInsgesamt erhalten wir:\n\n\\begin{align*}\n\\text{Var}(\\hat{\\beta}_1 | x) & = \\frac{\\sigma^2}{\\sum_{i=1}^{n}(x_i - \\bar{x})^2}\n\\end{align*}",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>ANOVA</span>"
    ]
  },
  {
    "objectID": "06-Multiples-Regressionsmodell.html",
    "href": "06-Multiples-Regressionsmodell.html",
    "title": "12  Multiples Regressionsmodell",
    "section": "",
    "text": "12.1 Cholera outbreak\nJohn Snow was an English physicist famous for locating the source of the London cholera epidemic of 1854. At the time of the outbreak the germ theory of disease transmission was not developed yet and cholera was blamed on bad air. John Snow investigated the cases and concluded that the source of the outbreak is a water pump located on Broad Street. He was able to convince the city council to close the pump but people initially resisted his theory of water born transmission, because it seemed to be socially unacceptable.",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Multiples Regressionsmodell</span>"
    ]
  },
  {
    "objectID": "06-Multiples-Regressionsmodell.html#cholera-outbreak",
    "href": "06-Multiples-Regressionsmodell.html#cholera-outbreak",
    "title": "12  Multiples Regressionsmodell",
    "section": "",
    "text": "Cholera cases\n\n\n\n\n\nBroad street pump",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Multiples Regressionsmodell</span>"
    ]
  },
  {
    "objectID": "06-Multiples-Regressionsmodell.html#world-war-ii",
    "href": "06-Multiples-Regressionsmodell.html#world-war-ii",
    "title": "12  Multiples Regressionsmodell",
    "section": "12.2 World War II",
    "text": "12.2 World War II\nDuring World war 2 combat aviation played a crucial role but also suffered heavy casualties. British bomber command for example reports a death rate of about 46 percent over the entire war. In order to reduce the number of planes that were being shot down during mission, the military collected data on the damage taken from returning bombers in order to decide where to place armour on the planes.\n\n\n\nFlight\n\n\n\n\n\nFlac damage on a bomber plane\n\n\n\n\n\nBullet holes locations (histogram)\n\n\n\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport geopandas as gpd\nfrom urllib.request import urlopen\nimport json\n\n# Read the data\ncrime = pd.read_csv(\"https://raw.githubusercontent.com/febse/data/main/econ/crime.csv\", delimiter=\"\\t\")\n\n# Drop the 'I' column\ncrime = crime.drop(columns=['I'])\n\n# Variables description:\n# 'C': number of crimes per 100,000 inhabitants\n# 'HS': share of high school graduates\n# 'U': share of persons living in urban areas\n\n# Code for illustration purposes only\nwith urlopen('https://raw.githubusercontent.com/plotly/datasets/master/geojson-counties-fips.json') as response:\n    counties = json.load(response)\n\n\nus_counties = gpd.GeoDataFrame.from_features(counties)\nus_counties[\"NAME\"] = us_counties[\"NAME\"].str.upper()\n\n\ncrime\n\n\n\n\n\n\n\n\nCounty\nC\nHS\nU\n\n\n\n\n0\nALACHUA\n104\n82.7\n73.2\n\n\n1\nBAKER\n20\n64.1\n21.5\n\n\n2\nBAY\n64\n74.7\n85.0\n\n\n3\nBRADFORD\n50\n65.0\n23.2\n\n\n4\nBREVARD\n64\n82.3\n91.9\n\n\n...\n...\n...\n...\n...\n\n\n62\nUNION\n6\n67.7\n0.0\n\n\n63\nVOLUSIA\n62\n75.4\n83.9\n\n\n64\nWAKULLA\n29\n71.6\n0.0\n\n\n65\nWALTON\n18\n66.5\n20.9\n\n\n66\nWASHING.\n21\n60.9\n22.9\n\n\n\n\n67 rows × 4 columns\n\n\n\n\n# Define county name compatibility\ncounty_name_compat = {\n  \"WASHINGTON\": \"WASHING\",\n  \"SANTA ROSA\": \"SANTAR\",\n  \"SUWANNEE\": \"SUWANEE\",\n  \"PALM BEACH\": \"PALMB\",\n  \"OKEECHOBEE\": \"OKEECH\",\n  \"INDIAN RIVER\": \"INDIANR\",\n  \"HILLSBOROUGH\": \"HILLSBOR.\",\n  \"MIAMI-DADE\": \"DADE\"\n}\n\n# Load US counties data\n# Replace 'us_counties.geojson' with your actual US counties GeoJSON file\n\nflorida_counties = us_counties[us_counties[\"STATE\"] == \"12\"].copy()\nflorida_counties[\"NAME\"] = florida_counties[\"NAME\"].replace(county_name_compat)\nflorida_counties[\"NAME\"] = florida_counties[\"NAME\"].replace(\"[\\s.]\", \"\", regex=True)\ncrime[\"County\"] = crime[\"County\"].replace(\"[\\s.]\", \"\", regex=True)\n# Filter for Florida counties\nfc = pd.merge(florida_counties, crime, right_on=\"County\", left_on=\"NAME\", how='right')\n\n\nimport matplotlib.pyplot as plt\n\n# Plot urbanisation\nfc.plot(column='U', legend=True)\nplt.title('Urbanisierung')\nplt.show()\n\n# Plot high school graduates\nfc.plot(column='HS', legend=True)\nplt.title(\"Bildung\")\nplt.show()\n\nfc.plot(column='C', legend=True)\nplt.title(\"Kriminalität\")\nplt.show()",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Multiples Regressionsmodell</span>"
    ]
  },
  {
    "objectID": "06-Multiples-Regressionsmodell.html#modell-4-kriminalität-bildung-und-urbanisierung",
    "href": "06-Multiples-Regressionsmodell.html#modell-4-kriminalität-bildung-und-urbanisierung",
    "title": "12  Multiples Regressionsmodell",
    "section": "16.1 Modell 4: Kriminalität, Bildung und Urbanisierung",
    "text": "16.1 Modell 4: Kriminalität, Bildung und Urbanisierung\n\n\\text{C}_i \\sim N(\\mu_i, \\sigma^2) \\\\\n\\mu_i = \\beta_0 + \\beta_1 \\text{HS}_i + \\beta_2 \\text{U}_i\n\n\n# Schätzen Sie das Modell\nmodell4 = ols('C ~ HS + U', data=fc).fit()\nmodell4.summary()\n\n\nOLS Regression Results\n\n\nDep. Variable:\nC\nR-squared:\n0.471\n\n\nModel:\nOLS\nAdj. R-squared:\n0.455\n\n\nMethod:\nLeast Squares\nF-statistic:\n28.54\n\n\nDate:\nSat, 08 Jun 2024\nProb (F-statistic):\n1.38e-09\n\n\nTime:\n12:42:02\nLog-Likelihood:\n-296.93\n\n\nNo. Observations:\n67\nAIC:\n599.9\n\n\nDf Residuals:\n64\nBIC:\n606.5\n\n\nDf Model:\n2\n\n\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\nIntercept\n59.1181\n28.365\n2.084\n0.041\n2.452\n115.784\n\n\nHS\n-0.5834\n0.472\n-1.235\n0.221\n-1.527\n0.360\n\n\nU\n0.6825\n0.123\n5.539\n0.000\n0.436\n0.929\n\n\n\n\n\n\nOmnibus:\n4.652\nDurbin-Watson:\n1.848\n\n\nProb(Omnibus):\n0.098\nJarque-Bera (JB):\n4.252\n\n\nSkew:\n0.543\nProb(JB):\n0.119\n\n\nKurtosis:\n2.414\nCond. No.\n997.\n\n\n\nNotes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\nSchätzen Sie die erwartete Kriminalitätsrate für eine County mit einer Urbanisierung von 0% und einer High School Abschlussrate 0%.\nSchätzen Sie die erwartete Kriminalitätsrate für eine County mit einem mittleren Urbanisierungsgrad und einer mittleren High School Abschlussrate\n\n\nimport numpy as np\n\ndef center(x):\n    return x - np.mean(x)\n\nols(\"C ~ center(HS) + center(U)\", data=fc).fit().summary()\n\n\nOLS Regression Results\n\n\nDep. Variable:\nC\nR-squared:\n0.471\n\n\nModel:\nOLS\nAdj. R-squared:\n0.455\n\n\nMethod:\nLeast Squares\nF-statistic:\n28.54\n\n\nDate:\nSat, 08 Jun 2024\nProb (F-statistic):\n1.38e-09\n\n\nTime:\n12:42:02\nLog-Likelihood:\n-296.93\n\n\nNo. Observations:\n67\nAIC:\n599.9\n\n\nDf Residuals:\n64\nBIC:\n606.5\n\n\nDf Model:\n2\n\n\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\nIntercept\n52.4030\n2.543\n20.607\n0.000\n47.323\n57.483\n\n\ncenter(HS)\n-0.5834\n0.472\n-1.235\n0.221\n-1.527\n0.360\n\n\ncenter(U)\n0.6825\n0.123\n5.539\n0.000\n0.436\n0.929\n\n\n\n\n\n\nOmnibus:\n4.652\nDurbin-Watson:\n1.848\n\n\nProb(Omnibus):\n0.098\nJarque-Bera (JB):\n4.252\n\n\nSkew:\n0.543\nProb(JB):\n0.119\n\n\nKurtosis:\n2.414\nCond. No.\n34.4\n\n\n\nNotes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\n# Normalize the predictors in such a way so that the \n# Intercept is the expected value of the dependent variable at the minimum value of the predictors\n# and the slope coefficients estimate the expected difference in the dependent variable for a change between the minimum and maximum value of the predictors\n\ndef norm_min_max(x):\n    return (x - np.min(x)) / (np.max(x) - np.min(x))\n\nols(\"C ~ norm_min_max(HS) + norm_min_max(U)\", data=fc).fit().summary()\n\n\nOLS Regression Results\n\n\nDep. Variable:\nC\nR-squared:\n0.471\n\n\nModel:\nOLS\nAdj. R-squared:\n0.455\n\n\nMethod:\nLeast Squares\nF-statistic:\n28.54\n\n\nDate:\nSat, 08 Jun 2024\nProb (F-statistic):\n1.38e-09\n\n\nTime:\n12:42:02\nLog-Likelihood:\n-296.93\n\n\nNo. Observations:\n67\nAIC:\n599.9\n\n\nDf Residuals:\n64\nBIC:\n606.5\n\n\nDf Model:\n2\n\n\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\nIntercept\n27.3240\n5.052\n5.409\n0.000\n17.232\n37.416\n\n\nnorm_min_max(HS)\n-17.7347\n14.363\n-1.235\n0.221\n-46.428\n10.958\n\n\nnorm_min_max(U)\n67.9771\n12.272\n5.539\n0.000\n43.461\n92.493\n\n\n\n\n\n\nOmnibus:\n4.652\nDurbin-Watson:\n1.848\n\n\nProb(Omnibus):\n0.098\nJarque-Bera (JB):\n4.252\n\n\nSkew:\n0.543\nProb(JB):\n0.119\n\n\nKurtosis:\n2.414\nCond. No.\n8.80\n\n\n\nNotes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Multiples Regressionsmodell</span>"
    ]
  },
  {
    "objectID": "07-NL.html",
    "href": "07-NL.html",
    "title": "13  Linearität",
    "section": "",
    "text": "13.1 Polynomiale Regression\n# Simulation\n\nx = np.random.normal(size=100, scale=4)\ny = 2 + 3*x**2 + np.random.normal(size=100, scale=20)\n\ndt = pd.DataFrame({\"x\": x, \"y\": y})\n\nsns.lmplot(data=dt, x=\"x\", y=\"y\")\nmod_lin = ols(\"y ~ x\", data=dt).fit()\n\ndt[\"resid_lin\"] = mod_lin.resid\n\nsns.lmplot(data=dt, x=\"x\", y=\"resid_lin\")\nmq = ols(\"y ~ x + I(x**2)\", data=dt).fit()\n\npred_mq = mq.get_prediction(dt).summary_frame()\n\ndt_with_pred = pd.concat([dt, pred_mq], axis=1)\ndt_with_pred.head()\n\n\n\n\n\n\n\n\nx\ny\nresid_lin\nmean\nmean_se\nmean_ci_lower\nmean_ci_upper\nobs_ci_lower\nobs_ci_upper\n\n\n\n\n0\n-3.793198\n40.193245\n-25.596574\n47.929551\n2.561017\n42.846641\n53.012461\n10.346788\n85.512313\n\n\n1\n2.486817\n14.597520\n-23.126300\n17.470682\n2.357258\n12.792178\n22.149186\n-20.059525\n55.000889\n\n\n2\n-0.799067\n-18.164259\n-70.573014\n3.959175\n2.416107\n-0.836128\n8.754478\n-33.585771\n41.504121\n\n\n3\n-2.967524\n52.302015\n-9.797787\n30.444918\n2.467313\n25.547985\n35.341851\n-7.113144\n68.002980\n\n\n4\n-4.019300\n54.650128\n-12.150165\n53.429361\n2.604750\n48.259653\n58.599069\n15.834761\n91.023961\nax = sns.scatterplot(x=\"x\", y=\"y\", data=dt_with_pred)\nsns.lineplot(x=\"x\", y=\"mean\", data=dt_with_pred, ax=ax)\n\ndt_sorted = dt_with_pred.sort_values(by=\"x\")\n\nax.fill_between(dt_sorted[\"x\"], dt_sorted[\"mean_ci_lower\"], dt_sorted[\"mean_ci_upper\"], color=\"gray\", alpha=0.5)\n\n/usr/share/miniconda/envs/econ2024/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning:\n\nuse_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n\n/usr/share/miniconda/envs/econ2024/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning:\n\nuse_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Linearität</span>"
    ]
  },
  {
    "objectID": "08-Interaction-Effects.html",
    "href": "08-Interaction-Effects.html",
    "title": "14  Interaktionseffekte",
    "section": "",
    "text": "14.1 Modell 1\nSchätzen Sie das folgende Modell:\n\\text{drink} = \\beta_0 + \\beta_1 \\text{gpa} + \\epsilon\n\\widehat{\\text{drink}} = \\hat{\\beta}_0 + \\hat{\\beta}_1 \\text{gpa}\nErläutern Sie, was \\hat{\\beta}_0 und \\hat{\\beta}_1 in diesem Modell schätzen.\nm1 = ols(\"drink ~ gpa\", data=df).fit()\nm1.summary()\n\n\nOLS Regression Results\n\n\nDep. Variable:\ndrink\nR-squared:\n0.080\n\n\nModel:\nOLS\nAdj. R-squared:\n0.075\n\n\nMethod:\nLeast Squares\nF-statistic:\n18.66\n\n\nDate:\nSat, 08 Jun 2024\nProb (F-statistic):\n2.38e-05\n\n\nTime:\n12:42:11\nLog-Likelihood:\n-715.71\n\n\nNo. Observations:\n218\nAIC:\n1435.\n\n\nDf Residuals:\n216\nBIC:\n1442.\n\n\nDf Model:\n1\n\n\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\nIntercept\n30.4436\n2.726\n11.167\n0.000\n25.070\n35.817\n\n\ngpa\n-4.1385\n0.958\n-4.320\n0.000\n-6.027\n-2.250\n\n\n\n\n\n\nOmnibus:\n1.871\nDurbin-Watson:\n1.878\n\n\nProb(Omnibus):\n0.392\nJarque-Bera (JB):\n1.842\n\n\nSkew:\n-0.156\nProb(JB):\n0.398\n\n\nKurtosis:\n2.675\nCond. No.\n19.8\n\n\n\nNotes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Interaktionseffekte</span>"
    ]
  },
  {
    "objectID": "08-Interaction-Effects.html#modell-2",
    "href": "08-Interaction-Effects.html#modell-2",
    "title": "14  Interaktionseffekte",
    "section": "14.2 Modell 2",
    "text": "14.2 Modell 2\nSchätzen Sie das folgende Modell:\n\n\\text{drink} = \\beta_0 + \\beta_1 \\text{gpa} + \\beta_2 \\text{male} + \\epsilon\n\n\n\\widehat{\\text{drink}} = \\hat{\\beta}_0 + \\hat{\\beta}_1 \\text{gpa} + \\hat{\\beta}_2 \\text{male}\n\nErläutern Sie, was \\hat{\\beta}_0, \\hat{\\beta}_1 und \\hat{\\beta}_2 in diesem Modell schätzen.\n\nm2 = ols(\"drink ~ gpa + male\", data=df).fit()\nm2.summary()\n\n\nOLS Regression Results\n\n\nDep. Variable:\ndrink\nR-squared:\n0.146\n\n\nModel:\nOLS\nAdj. R-squared:\n0.138\n\n\nMethod:\nLeast Squares\nF-statistic:\n18.36\n\n\nDate:\nSat, 08 Jun 2024\nProb (F-statistic):\n4.34e-08\n\n\nTime:\n12:42:11\nLog-Likelihood:\n-707.55\n\n\nNo. Observations:\n218\nAIC:\n1421.\n\n\nDf Residuals:\n215\nBIC:\n1431.\n\n\nDf Model:\n2\n\n\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\nIntercept\n26.9125\n2.770\n9.715\n0.000\n21.452\n32.373\n\n\ngpa\n-3.4529\n0.940\n-3.673\n0.000\n-5.306\n-1.600\n\n\nmale\n3.5358\n0.865\n4.088\n0.000\n1.831\n5.241\n\n\n\n\n\n\nOmnibus:\n6.437\nDurbin-Watson:\n1.920\n\n\nProb(Omnibus):\n0.040\nJarque-Bera (JB):\n5.082\n\n\nSkew:\n-0.270\nProb(JB):\n0.0788\n\n\nKurtosis:\n2.481\nCond. No.\n21.1\n\n\n\nNotes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\n# Die Modellschätzungen visualisieren\n\nm2p = m2.get_prediction().summary_frame()\nm2p_with_ci = pd.concat([df, m2p], axis=1)\n\nsns.scatterplot(x='gpa', y='drink', data=m2p_with_ci, hue=\"male\")\nsns.lineplot(x='gpa', y='mean', data=m2p_with_ci, hue=\"male\")\n\n/usr/share/miniconda/envs/econ2024/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning:\n\nuse_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n\n/usr/share/miniconda/envs/econ2024/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning:\n\nuse_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n\n/usr/share/miniconda/envs/econ2024/lib/python3.11/site-packages/seaborn/_oldcore.py:1075: FutureWarning:\n\nWhen grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n\n/usr/share/miniconda/envs/econ2024/lib/python3.11/site-packages/seaborn/_oldcore.py:1075: FutureWarning:\n\nWhen grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Interaktionseffekte</span>"
    ]
  },
  {
    "objectID": "08-Interaction-Effects.html#modell-3",
    "href": "08-Interaction-Effects.html#modell-3",
    "title": "14  Interaktionseffekte",
    "section": "14.3 Modell 3",
    "text": "14.3 Modell 3\nSchätzen Sie das folgende Modell:\n\n\\text{drink} = \\beta_0 + \\beta_1 \\text{gpa} + \\beta_2 \\text{male} + \\beta_3 \\text{gpa} \\times \\text{male} + \\epsilon\n\n\n\\widehat{\\text{drink}} = \\hat{\\beta}_0 + \\hat{\\beta}_1 \\text{gpa} + \\hat{\\beta}_2 \\text{male} + \\hat{\\beta}_3 \\text{gpa}\\times \\text{male}\n\nErläutern Sie, was \\hat{\\beta}_0, \\hat{\\beta}_1, \\hat{\\beta}_2 und \\hat{\\beta}_3 in diesem Modell schätzen.\n\nm3 = ols(\"drink ~ gpa*male\", data=df).fit()\nm3.params\nm3.summary()\n\n\nOLS Regression Results\n\n\nDep. Variable:\ndrink\nR-squared:\n0.148\n\n\nModel:\nOLS\nAdj. R-squared:\n0.136\n\n\nMethod:\nLeast Squares\nF-statistic:\n12.35\n\n\nDate:\nSat, 08 Jun 2024\nProb (F-statistic):\n1.76e-07\n\n\nTime:\n12:42:12\nLog-Likelihood:\n-707.34\n\n\nNo. Observations:\n218\nAIC:\n1423.\n\n\nDf Residuals:\n214\nBIC:\n1436.\n\n\nDf Model:\n3\n\n\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nt\nP&gt;|t|\n[0.025\n0.975]\n\n\nIntercept\n28.5221\n3.740\n7.627\n0.000\n21.151\n35.893\n\n\ngpa\n-4.0112\n1.282\n-3.129\n0.002\n-6.538\n-1.485\n\n\nmale\n0.1488\n5.348\n0.028\n0.978\n-10.393\n10.690\n\n\ngpa:male\n1.2121\n1.889\n0.642\n0.522\n-2.511\n4.935\n\n\n\n\n\n\nOmnibus:\n6.531\nDurbin-Watson:\n1.924\n\n\nProb(Omnibus):\n0.038\nJarque-Bera (JB):\n5.367\n\n\nSkew:\n-0.291\nProb(JB):\n0.0683\n\n\nKurtosis:\n2.498\nCond. No.\n50.7\n\n\n\nNotes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\nm3p = m3.get_prediction().summary_frame()\nm3p_with_ci = pd.concat([df, m3p], axis=1)\nm3p_with_ci.head()\n\n\n\n\n\n\n\n\nmale\ndrink\ngpa\nmean\nmean_se\nmean_ci_lower\nmean_ci_upper\nobs_ci_lower\nobs_ci_upper\n\n\n\n\n0\n1\n5\n3.20\n19.713625\n0.917598\n17.904938\n21.522312\n7.232428\n32.194822\n\n\n1\n0\n9\n3.00\n16.488436\n0.593608\n15.318369\n17.658503\n4.083680\n28.893192\n\n\n2\n1\n29\n2.85\n20.693325\n0.655452\n19.401357\n21.985293\n8.276478\n33.110172\n\n\n3\n0\n22\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n4\n0\n19\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n\n\n\n\nsns.lmplot(x='gpa', y='drink', hue=\"male\", data=df)\n\n\n\n\n\n\n\n\n\n\n\n\nWard, Sally, und Susan Ault. 1990. „AIDS Knowledge, Fear, and Safe Sex Practices on Campus“. Sociology and Social Research 74 (3): 158–61.",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Interaktionseffekte</span>"
    ]
  },
  {
    "objectID": "Literature.html",
    "href": "Literature.html",
    "title": "Empfohlene Literatur",
    "section": "",
    "text": "James u. a. (2023)\n\nDas Lehrbuch ist eine Einführung in die statistische Lerntheorie und behandelt das lineare Regressionsmodell, das der Kern des Kurses ist. Enthalten sind Beispielanwendungen in Python.\n\nMcKinney (2022)\n\nDas Buch ist eine Einführung in die Datenanalyse mit Python und behandelt die Grundlagen der Programmiersprache und der Datenanalyse. Es ist ein guter Einstieg in die Programmierung mit Python.\n\nGelman, Hill, und Vehtari (2021):\n\nRegression and other stories. Cambridge New York, NY Port Melbourne, VIC New Delhi Singapore: Cambridge University Press (Analytical methods for social research). Available at: https://doi.org/10.1017/9781139161879.\n\n\n\n\nGelman, Andrew, Jennifer Hill, und Aki Vehtari. 2021. Regression and Other Stories. Analytical Methods for Social Research. Cambridge New York, NY Port Melbourne, VIC New Delhi Singapore: Cambridge University Press. https://doi.org/10.1017/9781139161879.\n\n\nJames, Gareth, Daniela Witten, Trevor Hastie, Robert Tibshirani, und Jonathan Taylor. 2023. An Introduction to Statistical Learning with Applications in Python. Cham: Springer International Publishing.\n\n\nMcKinney, Wes. 2022. Python for Data Analysis: Data Wrangling with Pandas, NumPy, and Jupyter. Third edition. Beijing Boston Farnham Sebastopol Tokyo: O’Reilly.",
    "crumbs": [
      "Empfohlene Literatur"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Literaturverzeichnis",
    "section": "",
    "text": "Gelman, Andrew, Jennifer Hill, and Aki Vehtari. 2021. Regression and\nOther Stories. Analytical Methods for Social Research.\nCambridge New York, NY Port Melbourne, VIC New Delhi\nSingapore: Cambridge University Press. https://doi.org/10.1017/9781139161879.\n\n\nJames, Gareth, Daniela Witten, Trevor Hastie, Robert Tibshirani, and\nJonathan Taylor. 2023. An Introduction to\nStatistical Learning with Applications in\nPython. Cham: Springer\nInternational Publishing.\n\n\nMcKinney, Wes. 2022. Python for Data Analysis: Data Wrangling with\nPandas, NumPy, and Jupyter.\nThird edition. Beijing Boston Farnham Sebastopol Tokyo:\nO’Reilly.\n\n\nWard, Sally, and Susan Ault. 1990. “AIDS Knowledge,\nFear, and Safe Sex Practices on Campus.” Sociology and Social\nResearch 74 (3): 158–61.",
    "crumbs": [
      "Literaturverzeichnis"
    ]
  }
]